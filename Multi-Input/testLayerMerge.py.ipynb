{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import keras\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import newaxis\n",
    "from keras.layers.core import  Activation, Dropout\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding,LSTM, Dense,TimeDistributed\n",
    "from keras import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "#from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#from keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(),list()\n",
    "    for i in range(n_in, 0 ,-1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1,i)) for j in range(n_vars)]\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    agg = concat(cols, axis =1)\n",
    "    agg.columns = names\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace = True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_stock = read_csv('fai1.csv', header = 0, index_col=0)\n",
    "values_stock = dataset_stock.values\n",
    "encoder = LabelEncoder()\n",
    "values_stock[:,0] = encoder.fit_transform(values_stock[:,0])\n",
    "values_stock = values_stock.astype('float32')\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_stock = scaler.fit_transform(values_stock)\n",
    "reframed_stock = series_to_supervised(scaled_stock, 1, 1)\n",
    "#reframed.drop(reframed.columns[[9,10,11,12,13,14,15]], axis = 1, inplace=True)\n",
    "print(reframed_stock.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 402.]\n",
      " [ 391.]\n",
      " [ 429.]\n",
      " [ 384.]\n",
      " [ 417.]\n",
      " [ 383.]\n",
      " [ 410.]\n",
      " [ 387.]\n",
      " [ 384.]\n",
      " [ 383.]\n",
      " [ 407.]\n",
      " [ 407.]\n",
      " [ 370.]\n",
      " [ 413.]\n",
      " [ 447.]\n",
      " [ 451.]\n",
      " [ 403.]\n",
      " [ 396.]\n",
      " [ 409.]\n",
      " [ 380.]\n",
      " [ 398.]\n",
      " [ 397.]\n",
      " [ 423.]\n",
      " [ 417.]\n",
      " [ 382.]\n",
      " [ 393.]\n",
      " [ 423.]\n",
      " [ 433.]\n",
      " [ 390.]\n",
      " [ 399.]\n",
      " [ 398.]\n",
      " [ 389.]\n",
      " [ 371.]\n",
      " [ 389.]\n",
      " [ 409.]\n",
      " [ 364.]\n",
      " [ 389.]\n",
      " [ 403.]\n",
      " [ 375.]\n",
      " [ 361.]\n",
      " [ 405.]\n",
      " [ 401.]\n",
      " [ 407.]\n",
      " [ 372.]\n",
      " [ 423.]\n",
      " [ 418.]\n",
      " [ 394.]\n",
      " [ 374.]\n",
      " [ 362.]\n",
      " [ 402.]\n",
      " [ 397.]\n",
      " [ 383.]\n",
      " [ 386.]\n",
      " [ 396.]\n",
      " [ 417.]\n",
      " [ 397.]\n",
      " [ 400.]\n",
      " [ 381.]\n",
      " [ 387.]\n",
      " [ 417.]\n",
      " [ 443.]\n",
      " [ 391.]\n",
      " [ 412.]\n",
      " [ 379.]\n",
      " [ 416.]\n",
      " [ 384.]\n",
      " [ 400.]\n",
      " [ 411.]\n",
      " [ 442.]\n",
      " [ 417.]\n",
      " [ 406.]\n",
      " [ 389.]\n",
      " [ 417.]\n",
      " [ 420.]\n",
      " [ 384.]\n",
      " [ 423.]\n",
      " [ 396.]\n",
      " [ 375.]\n",
      " [ 363.]\n",
      " [ 358.]\n",
      " [ 407.]\n",
      " [ 406.]\n",
      " [ 409.]\n",
      " [ 419.]\n",
      " [ 396.]\n",
      " [ 382.]\n",
      " [ 406.]\n",
      " [ 398.]\n",
      " [ 342.]\n",
      " [ 408.]\n",
      " [ 384.]\n",
      " [ 428.]\n",
      " [ 395.]\n",
      " [ 409.]\n",
      " [ 402.]\n",
      " [ 396.]\n",
      " [ 372.]\n",
      " [ 454.]\n",
      " [ 419.]\n",
      " [ 401.]\n",
      " [ 396.]\n",
      " [ 383.]\n",
      " [ 395.]\n",
      " [ 392.]\n",
      " [ 414.]\n",
      " [ 411.]\n",
      " [ 385.]\n",
      " [ 415.]\n",
      " [ 440.]\n",
      " [ 407.]\n",
      " [ 429.]\n",
      " [ 396.]\n",
      " [ 401.]\n",
      " [ 370.]\n",
      " [ 404.]\n",
      " [ 393.]\n",
      " [ 399.]\n",
      " [ 368.]\n",
      " [ 407.]\n",
      " [ 395.]\n",
      " [ 390.]\n",
      " [ 379.]\n",
      " [ 367.]\n",
      " [ 417.]\n",
      " [ 406.]\n",
      " [ 401.]\n",
      " [ 401.]\n",
      " [ 382.]\n",
      " [ 405.]\n",
      " [ 396.]\n",
      " [ 441.]\n",
      " [ 398.]\n",
      " [ 397.]\n",
      " [ 377.]\n",
      " [ 402.]\n",
      " [ 379.]\n",
      " [ 403.]\n",
      " [ 416.]\n",
      " [ 397.]\n",
      " [ 413.]\n",
      " [ 407.]\n",
      " [ 393.]\n",
      " [ 416.]\n",
      " [ 390.]\n",
      " [ 399.]\n",
      " [ 399.]\n",
      " [ 386.]\n",
      " [ 416.]\n",
      " [ 389.]\n",
      " [ 401.]\n",
      " [ 422.]\n",
      " [ 402.]\n",
      " [ 397.]\n",
      " [ 419.]\n",
      " [ 415.]\n",
      " [ 381.]\n",
      " [ 389.]\n",
      " [ 368.]\n",
      " [ 403.]\n",
      " [ 398.]\n",
      " [ 409.]\n",
      " [ 392.]\n",
      " [ 413.]\n",
      " [ 398.]\n",
      " [ 402.]\n",
      " [ 412.]\n",
      " [ 409.]\n",
      " [ 404.]\n",
      " [ 396.]\n",
      " [ 400.]\n",
      " [ 405.]\n",
      " [ 374.]\n",
      " [ 400.]\n",
      " [ 408.]\n",
      " [ 420.]\n",
      " [ 404.]\n",
      " [ 397.]\n",
      " [ 388.]\n",
      " [ 404.]\n",
      " [ 395.]\n",
      " [ 421.]\n",
      " [ 403.]\n",
      " [ 427.]\n",
      " [ 421.]\n",
      " [ 451.]\n",
      " [ 406.]\n",
      " [ 398.]\n",
      " [ 420.]\n",
      " [ 384.]\n",
      " [ 438.]\n",
      " [ 396.]\n",
      " [ 398.]\n",
      " [ 370.]\n",
      " [ 407.]\n",
      " [ 430.]\n",
      " [ 397.]\n",
      " [ 401.]\n",
      " [ 384.]\n",
      " [ 420.]\n",
      " [ 413.]\n",
      " [ 406.]\n",
      " [ 395.]\n",
      " [ 390.]\n",
      " [ 410.]\n",
      " [ 389.]\n",
      " [ 378.]\n",
      " [ 402.]\n",
      " [ 350.]\n",
      " [ 458.]\n",
      " [ 418.]\n",
      " [ 431.]\n",
      " [ 422.]\n",
      " [ 418.]\n",
      " [ 420.]\n",
      " [ 389.]\n",
      " [ 403.]\n",
      " [ 393.]\n",
      " [ 420.]\n",
      " [ 408.]\n",
      " [ 357.]\n",
      " [ 411.]\n",
      " [ 408.]\n",
      " [ 414.]\n",
      " [ 360.]\n",
      " [ 420.]\n",
      " [ 434.]\n",
      " [ 402.]\n",
      " [ 402.]\n",
      " [ 410.]\n",
      " [ 406.]\n",
      " [ 419.]\n",
      " [ 407.]\n",
      " [ 385.]\n",
      " [ 392.]\n",
      " [ 393.]\n",
      " [ 414.]\n",
      " [ 383.]\n",
      " [ 385.]\n",
      " [ 415.]\n",
      " [ 383.]\n",
      " [ 387.]\n",
      " [ 376.]\n",
      " [ 400.]\n",
      " [ 388.]\n",
      " [ 447.]\n",
      " [ 436.]\n",
      " [ 418.]\n",
      " [ 429.]\n",
      " [ 410.]\n",
      " [ 400.]\n",
      " [ 389.]\n",
      " [ 406.]\n",
      " [ 393.]\n",
      " [ 455.]\n",
      " [ 396.]\n",
      " [ 425.]\n",
      " [ 391.]\n",
      " [ 393.]\n",
      " [ 396.]\n",
      " [ 382.]\n",
      " [ 394.]\n",
      " [ 402.]\n",
      " [ 434.]\n",
      " [ 446.]\n",
      " [ 435.]\n",
      " [ 437.]\n",
      " [ 426.]\n",
      " [ 452.]\n",
      " [ 398.]\n",
      " [ 483.]\n",
      " [ 416.]\n",
      " [ 520.]\n",
      " [ 438.]\n",
      " [ 483.]\n",
      " [ 236.]\n",
      " [ 484.]\n",
      " [ 385.]\n",
      " [ 413.]\n",
      " [ 415.]\n",
      " [ 468.]\n",
      " [ 440.]\n",
      " [ 396.]\n",
      " [ 451.]\n",
      " [ 419.]\n",
      " [ 305.]\n",
      " [ 340.]\n",
      " [ 500.]\n",
      " [ 485.]\n",
      " [ 411.]\n",
      " [ 397.]\n",
      " [ 469.]\n",
      " [ 516.]\n",
      " [ 401.]\n",
      " [ 422.]\n",
      " [ 320.]\n",
      " [ 392.]\n",
      " [ 344.]\n",
      " [ 406.]\n",
      " [ 387.]\n",
      " [ 514.]\n",
      " [ 440.]\n",
      " [ 140.]\n",
      " [ 457.]\n",
      " [ 550.]\n",
      " [ 420.]\n",
      " [ 408.]\n",
      " [ 432.]\n",
      " [ 369.]\n",
      " [ 353.]\n",
      " [ 357.]\n",
      " [ 348.]\n",
      " [ 318.]\n",
      " [ 476.]\n",
      " [ 370.]\n",
      " [ 362.]\n",
      " [ 339.]\n",
      " [ 420.]\n",
      " [ 446.]\n",
      " [ 398.]\n",
      " [ 434.]\n",
      " [ 430.]\n",
      " [ 419.]\n",
      " [ 424.]\n",
      " [ 382.]\n",
      " [ 470.]\n",
      " [ 412.]\n",
      " [ 426.]\n",
      " [ 327.]\n",
      " [ 416.]\n",
      " [ 369.]\n",
      " [ 393.]\n",
      " [ 461.]\n",
      " [ 384.]\n",
      " [ 404.]\n",
      " [ 459.]\n",
      " [ 423.]\n",
      " [ 477.]\n",
      " [ 453.]\n",
      " [ 475.]\n",
      " [ 405.]\n",
      " [ 435.]\n",
      " [ 470.]\n",
      " [ 404.]\n",
      " [ 369.]\n",
      " [ 422.]\n",
      " [ 409.]\n",
      " [ 495.]\n",
      " [ 361.]\n",
      " [ 463.]\n",
      " [ 415.]\n",
      " [ 438.]\n",
      " [ 498.]\n",
      " [ 433.]\n",
      " [ 363.]\n",
      " [ 477.]\n",
      " [ 487.]\n",
      " [ 414.]\n",
      " [ 349.]\n",
      " [ 510.]\n",
      " [ 493.]\n",
      " [ 330.]\n",
      " [ 476.]\n",
      " [ 505.]\n",
      " [ 416.]\n",
      " [ 379.]\n",
      " [ 534.]\n",
      " [ 349.]\n",
      " [ 400.]\n",
      " [ 365.]\n",
      " [ 439.]\n",
      " [ 218.]\n",
      " [ 331.]\n",
      " [ 283.]\n",
      " [ 493.]\n",
      " [ 528.]\n",
      " [ 468.]\n",
      " [ 374.]\n",
      " [ 403.]\n",
      " [ 330.]\n",
      " [ 375.]\n",
      " [ 534.]\n",
      " [ 429.]\n",
      " [ 483.]\n",
      " [ 528.]\n",
      " [ 556.]\n",
      " [ 497.]\n",
      " [ 431.]\n",
      " [  79.]\n",
      " [ 391.]\n",
      " [ 617.]\n",
      " [ 482.]\n",
      " [ 399.]\n",
      " [ 438.]\n",
      " [ 476.]\n",
      " [ 508.]\n",
      " [ 382.]\n",
      " [ 393.]\n",
      " [ 415.]\n",
      " [ 445.]\n",
      " [ 296.]\n",
      " [ 225.]\n",
      " [ 480.]\n",
      " [ 218.]\n",
      " [  93.]\n",
      " [ 498.]\n",
      " [ 514.]\n",
      " [ 237.]\n",
      " [  65.]\n",
      " [ 261.]\n",
      " [ 624.]\n",
      " [ 176.]\n",
      " [ 259.]\n",
      " [ 174.]\n",
      " [ 489.]\n",
      " [ 352.]\n",
      " [ 180.]\n",
      " [ 602.]\n",
      " [ 568.]\n",
      " [ 493.]\n",
      " [ 354.]\n",
      " [ 281.]\n",
      " [ 418.]\n",
      " [ 534.]\n",
      " [ 435.]\n",
      " [ 425.]\n",
      " [ 409.]\n",
      " [ 497.]\n",
      " [ 347.]\n",
      " [  55.]\n",
      " [ 338.]\n",
      " [ 526.]\n",
      " [ 316.]\n",
      " [ 358.]\n",
      " [ 359.]\n",
      " [ 534.]\n",
      " [ 338.]\n",
      " [ 367.]\n",
      " [ 483.]\n",
      " [ 584.]\n",
      " [ 399.]\n",
      " [ 359.]\n",
      " [ 468.]\n",
      " [ 411.]\n",
      " [ 428.]\n",
      " [ 155.]\n",
      " [ 446.]\n",
      " [ 270.]\n",
      " [ 243.]\n",
      " [ 102.]\n",
      " [ 155.]\n",
      " [ 408.]\n",
      " [ 511.]\n",
      " [ 549.]\n",
      " [ 373.]\n",
      " [ 361.]\n",
      " [ 394.]\n",
      " [ 320.]\n",
      " [ 490.]\n",
      " [ 473.]\n",
      " [ 354.]\n",
      " [ 403.]\n",
      " [ 314.]\n",
      " [ 291.]\n",
      " [ 547.]\n",
      " [ 334.]\n",
      " [ 411.]\n",
      " [ 459.]\n",
      " [ 429.]\n",
      " [ 330.]\n",
      " [ 427.]\n",
      " [ 350.]\n",
      " [ 408.]\n",
      " [ 338.]\n",
      " [ 414.]\n",
      " [ 491.]\n",
      " [ 440.]\n",
      " [ 504.]\n",
      " [ 406.]\n",
      " [ 369.]\n",
      " [ 476.]\n",
      " [ 453.]\n",
      " [ 395.]\n",
      " [ 439.]\n",
      " [ 295.]\n",
      " [ 448.]\n",
      " [ 444.]\n",
      " [ 417.]\n",
      " [ 405.]\n",
      " [ 341.]\n",
      " [ 412.]\n",
      " [ 395.]\n",
      " [ 343.]\n",
      " [ 391.]\n",
      " [ 543.]\n",
      " [ 463.]\n",
      " [ 524.]\n",
      " [ 400.]\n",
      " [ 394.]\n",
      " [ 410.]\n",
      " [ 382.]\n",
      " [ 348.]\n",
      " [ 426.]\n",
      " [ 398.]\n",
      " [ 364.]\n",
      " [ 449.]\n",
      " [ 413.]\n",
      " [ 380.]\n",
      " [ 406.]\n",
      " [ 430.]\n",
      " [ 389.]\n",
      " [ 201.]\n",
      " [ 409.]\n",
      " [ 411.]\n",
      " [ 480.]\n",
      " [ 448.]\n",
      " [ 340.]\n",
      " [ 412.]\n",
      " [ 334.]\n",
      " [ 402.]\n",
      " [ 383.]\n",
      " [ 379.]\n",
      " [ 486.]\n",
      " [ 390.]\n",
      " [ 406.]\n",
      " [ 464.]\n",
      " [ 398.]\n",
      " [ 464.]\n",
      " [ 409.]\n",
      " [ 385.]\n",
      " [ 376.]\n",
      " [ 415.]\n",
      " [ 306.]\n",
      " [ 430.]\n",
      " [ 409.]\n",
      " [ 367.]\n",
      " [ 157.]\n",
      " [ 391.]\n",
      " [ 474.]\n",
      " [ 164.]\n",
      " [ 461.]\n",
      " [ 230.]\n",
      " [ 406.]\n",
      " [ 327.]\n",
      " [ 458.]\n",
      " [ 293.]\n",
      " [ 413.]\n",
      " [ 494.]\n",
      " [ 369.]\n",
      " [ 304.]\n",
      " [ 436.]\n",
      " [ 422.]\n",
      " [ 211.]\n",
      " [ 386.]\n",
      " [ 320.]\n",
      " [ 482.]\n",
      " [ 351.]\n",
      " [ 461.]\n",
      " [ 390.]\n",
      " [ 442.]\n",
      " [ 382.]\n",
      " [ 383.]\n",
      " [ 490.]\n",
      " [ 431.]\n",
      " [ 395.]\n",
      " [ 398.]\n",
      " [ 467.]\n",
      " [ 376.]\n",
      " [ 425.]\n",
      " [ 213.]\n",
      " [ 426.]\n",
      " [ 320.]\n",
      " [ 446.]\n",
      " [ 516.]\n",
      " [ 410.]\n",
      " [ 415.]\n",
      " [ 423.]\n",
      " [ 404.]\n",
      " [ 361.]\n",
      " [ 342.]\n",
      " [ 406.]\n",
      " [ 449.]\n",
      " [ 405.]\n",
      " [ 406.]\n",
      " [ 434.]\n",
      " [ 451.]\n",
      " [ 463.]\n",
      " [ 381.]\n",
      " [ 410.]\n",
      " [ 351.]\n",
      " [ 419.]\n",
      " [ 378.]\n",
      " [ 362.]\n",
      " [ 481.]\n",
      " [ 403.]\n",
      " [ 406.]\n",
      " [ 444.]\n",
      " [ 397.]\n",
      " [ 358.]\n",
      " [ 376.]\n",
      " [ 449.]\n",
      " [ 390.]\n",
      " [ 443.]\n",
      " [ 416.]\n",
      " [ 396.]\n",
      " [ 355.]\n",
      " [ 409.]\n",
      " [ 330.]\n",
      " [ 380.]\n",
      " [ 407.]\n",
      " [ 387.]\n",
      " [ 418.]\n",
      " [ 389.]\n",
      " [ 392.]\n",
      " [ 393.]\n",
      " [ 454.]\n",
      " [ 399.]\n",
      " [ 406.]\n",
      " [ 316.]\n",
      " [ 319.]\n",
      " [ 400.]\n",
      " [ 405.]\n",
      " [ 398.]\n",
      " [ 392.]\n",
      " [ 423.]\n",
      " [ 393.]\n",
      " [ 364.]\n",
      " [ 399.]\n",
      " [ 419.]\n",
      " [ 418.]\n",
      " [ 378.]\n",
      " [ 394.]\n",
      " [ 407.]\n",
      " [ 399.]\n",
      " [ 401.]\n",
      " [ 494.]\n",
      " [ 397.]\n",
      " [ 412.]\n",
      " [ 413.]\n",
      " [ 396.]\n",
      " [ 402.]\n",
      " [ 391.]\n",
      " [ 306.]\n",
      " [ 409.]\n",
      " [ 445.]\n",
      " [ 385.]\n",
      " [ 413.]\n",
      " [ 403.]\n",
      " [ 390.]\n",
      " [ 427.]\n",
      " [ 386.]\n",
      " [ 363.]\n",
      " [ 441.]\n",
      " [ 417.]\n",
      " [ 419.]\n",
      " [ 398.]\n",
      " [ 403.]\n",
      " [ 456.]\n",
      " [ 418.]\n",
      " [ 411.]\n",
      " [ 399.]\n",
      " [ 372.]\n",
      " [ 406.]\n",
      " [ 455.]\n",
      " [ 411.]\n",
      " [ 394.]\n",
      " [ 400.]\n",
      " [ 380.]\n",
      " [ 402.]\n",
      " [ 391.]\n",
      " [ 412.]\n",
      " [ 373.]\n",
      " [ 403.]\n",
      " [ 435.]\n",
      " [ 342.]\n",
      " [ 402.]\n",
      " [ 385.]\n",
      " [ 374.]\n",
      " [ 418.]\n",
      " [ 407.]]\n"
     ]
    }
   ],
   "source": [
    "dataset_gap = read_csv('gap1.csv', header = 0, index_col=0)\n",
    "values_gap = dataset_gap.values\n",
    "#encoder = LabelEncoder()\n",
    "#values_gap[:,0] = encoder.fit_transform(values_gap[:,0])\n",
    "values_gap = values_gap.astype('float32')\n",
    "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#scaled_gap = scaler.fit_transform(values_gap)\n",
    "#reframed_gap = series_to_supervised(scaled_gap, 1, 1)\n",
    "#reframed.drop(reframed.columns[[9,10,11,12,13,14,15]], axis = 1, inplace=True)\n",
    "#print(reframed_gap.head())\n",
    "print values_gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 13.10000038]\n",
      " [ 13.19999981]\n",
      " [ 13.10000038]\n",
      " [ 13.19999981]\n",
      " [ 13.10000038]\n",
      " [ 11.69999981]\n",
      " [ 11.60000038]\n",
      " [ 11.69999981]\n",
      " [ 11.60000038]\n",
      " [ 11.60000038]\n",
      " [ 15.69999981]\n",
      " [ 15.69999981]\n",
      " [ 15.69999981]\n",
      " [ 15.69999981]\n",
      " [ 15.69999981]\n",
      " [ 19.29999924]\n",
      " [ 19.29999924]\n",
      " [ 19.39999962]\n",
      " [ 19.29999924]\n",
      " [ 19.39999962]\n",
      " [ 15.60000038]\n",
      " [ 15.60000038]\n",
      " [ 15.60000038]\n",
      " [ 15.60000038]\n",
      " [ 15.69999981]\n",
      " [ 14.        ]\n",
      " [ 14.        ]\n",
      " [ 14.        ]\n",
      " [ 14.10000038]\n",
      " [ 14.10000038]\n",
      " [  8.69999981]\n",
      " [  8.69999981]\n",
      " [  8.69999981]\n",
      " [  8.60000038]\n",
      " [  8.60000038]\n",
      " [ 16.79999924]\n",
      " [ 16.79999924]\n",
      " [ 16.79999924]\n",
      " [ 16.79999924]\n",
      " [ 16.79999924]\n",
      " [ 12.89999962]\n",
      " [ 12.89999962]\n",
      " [ 12.89999962]\n",
      " [ 12.89999962]\n",
      " [ 12.89999962]\n",
      " [ 12.89999962]\n",
      " [ 12.89999962]\n",
      " [ 12.89999962]\n",
      " [ 12.89999962]\n",
      " [ 16.39999962]\n",
      " [ 16.39999962]\n",
      " [ 16.39999962]\n",
      " [ 16.39999962]\n",
      " [ 16.39999962]\n",
      " [ 14.10000038]\n",
      " [ 14.19999981]\n",
      " [ 14.10000038]\n",
      " [ 14.10000038]\n",
      " [ 14.10000038]\n",
      " [ 15.        ]\n",
      " [ 15.        ]\n",
      " [ 15.        ]\n",
      " [ 15.        ]\n",
      " [ 15.        ]\n",
      " [ 11.80000019]\n",
      " [ 11.80000019]\n",
      " [ 11.80000019]\n",
      " [ 11.80000019]\n",
      " [ 11.89999962]\n",
      " [ 14.89999962]\n",
      " [ 15.        ]\n",
      " [ 15.        ]\n",
      " [ 15.        ]\n",
      " [ 15.        ]\n",
      " [ 12.80000019]\n",
      " [ 12.80000019]\n",
      " [ 12.89999962]\n",
      " [ 12.80000019]\n",
      " [ 12.80000019]\n",
      " [ 17.70000076]\n",
      " [ 17.70000076]\n",
      " [ 17.70000076]\n",
      " [ 17.70000076]\n",
      " [ 17.70000076]\n",
      " [ 15.89999962]\n",
      " [ 15.89999962]\n",
      " [ 15.80000019]\n",
      " [ 15.80000019]\n",
      " [ 15.80000019]\n",
      " [ 16.        ]\n",
      " [ 16.        ]\n",
      " [ 16.        ]\n",
      " [ 16.10000038]\n",
      " [ 16.        ]\n",
      " [ 18.        ]\n",
      " [ 18.        ]\n",
      " [ 17.89999962]\n",
      " [ 17.89999962]\n",
      " [ 18.        ]\n",
      " [ 20.79999924]\n",
      " [ 20.79999924]\n",
      " [ 20.79999924]\n",
      " [ 20.70000076]\n",
      " [ 20.70000076]\n",
      " [ 11.5       ]\n",
      " [ 11.5       ]\n",
      " [ 11.60000038]\n",
      " [ 11.5       ]\n",
      " [ 11.60000038]\n",
      " [ 12.30000019]\n",
      " [ 12.30000019]\n",
      " [ 12.30000019]\n",
      " [ 12.30000019]\n",
      " [ 12.19999981]\n",
      " [ 12.10000038]\n",
      " [ 12.10000038]\n",
      " [ 12.10000038]\n",
      " [ 12.10000038]\n",
      " [ 14.19999981]\n",
      " [ 14.30000019]\n",
      " [ 14.19999981]\n",
      " [ 14.19999981]\n",
      " [ 14.19999981]\n",
      " [ 15.69999981]\n",
      " [ 15.80000019]\n",
      " [ 15.80000019]\n",
      " [ 14.19999981]\n",
      " [ 14.19999981]\n",
      " [ 14.10000038]\n",
      " [ 14.10000038]\n",
      " [ 14.10000038]\n",
      " [ 13.        ]\n",
      " [ 13.        ]\n",
      " [ 13.        ]\n",
      " [ 12.89999962]\n",
      " [ 13.        ]\n",
      " [  8.80000019]\n",
      " [  8.80000019]\n",
      " [  8.89999962]\n",
      " [  8.89999962]\n",
      " [  8.89999962]\n",
      " [  9.69999981]\n",
      " [  9.69999981]\n",
      " [  9.69999981]\n",
      " [  9.69999981]\n",
      " [  9.69999981]\n",
      " [ 19.60000038]\n",
      " [ 19.60000038]\n",
      " [ 19.70000076]\n",
      " [ 19.60000038]\n",
      " [ 26.29999924]\n",
      " [ 26.39999962]\n",
      " [ 26.39999962]\n",
      " [ 26.29999924]\n",
      " [ 26.39999962]\n",
      " [ 14.80000019]\n",
      " [ 14.69999981]\n",
      " [ 14.69999981]\n",
      " [ 14.69999981]\n",
      " [ 14.69999981]\n",
      " [ 13.89999962]\n",
      " [ 13.89999962]\n",
      " [ 13.89999962]\n",
      " [ 13.89999962]\n",
      " [ 13.89999962]\n",
      " [ 17.60000038]\n",
      " [ 17.60000038]\n",
      " [ 17.70000076]\n",
      " [ 17.70000076]\n",
      " [ 17.70000076]\n",
      " [ 25.        ]\n",
      " [ 25.        ]\n",
      " [ 25.        ]\n",
      " [ 25.        ]\n",
      " [ 25.        ]\n",
      " [ 17.20000076]\n",
      " [ 17.29999924]\n",
      " [ 17.29999924]\n",
      " [ 17.20000076]\n",
      " [ 17.20000076]\n",
      " [ 14.30000019]\n",
      " [ 14.30000019]\n",
      " [ 14.30000019]\n",
      " [ 14.30000019]\n",
      " [ 14.30000019]\n",
      " [ 14.        ]\n",
      " [ 14.10000038]\n",
      " [ 14.        ]\n",
      " [ 14.10000038]\n",
      " [ 14.10000038]\n",
      " [ 22.79999924]\n",
      " [ 22.79999924]\n",
      " [ 22.79999924]\n",
      " [ 22.79999924]\n",
      " [ 22.79999924]\n",
      " [ 17.70000076]\n",
      " [ 17.70000076]\n",
      " [ 17.70000076]\n",
      " [ 17.70000076]\n",
      " [ 17.70000076]\n",
      " [ 15.10000038]\n",
      " [ 15.10000038]\n",
      " [ 15.10000038]\n",
      " [ 15.10000038]\n",
      " [ 15.10000038]\n",
      " [ 23.5       ]\n",
      " [ 23.5       ]\n",
      " [ 23.5       ]\n",
      " [ 23.5       ]\n",
      " [ 23.5       ]\n",
      " [ 20.5       ]\n",
      " [ 20.5       ]\n",
      " [ 20.5       ]\n",
      " [ 20.5       ]\n",
      " [ 20.5       ]\n",
      " [ 15.5       ]\n",
      " [ 15.5       ]\n",
      " [ 15.5       ]\n",
      " [ 15.5       ]\n",
      " [ 18.70000076]\n",
      " [ 18.70000076]\n",
      " [ 18.70000076]\n",
      " [ 18.70000076]\n",
      " [ 18.70000076]\n",
      " [ 17.20000076]\n",
      " [ 17.20000076]\n",
      " [ 17.20000076]\n",
      " [ 17.20000076]\n",
      " [ 17.20000076]\n",
      " [ 21.20000076]\n",
      " [ 21.20000076]\n",
      " [ 30.20000076]\n",
      " [ 30.20000076]\n",
      " [ 30.20000076]\n",
      " [ 35.90000153]\n",
      " [ 35.90000153]\n",
      " [ 35.90000153]\n",
      " [ 35.90000153]\n",
      " [ 35.90000153]\n",
      " [ 16.70000076]\n",
      " [ 16.70000076]\n",
      " [ 16.70000076]\n",
      " [ 16.70000076]\n",
      " [ 16.70000076]\n",
      " [ 14.89999962]\n",
      " [ 14.89999962]\n",
      " [ 14.89999962]\n",
      " [ 14.89999962]\n",
      " [ 14.89999962]\n",
      " [ 27.39999962]\n",
      " [ 27.39999962]\n",
      " [ 27.39999962]\n",
      " [ 27.39999962]\n",
      " [ 27.39999962]\n",
      " [ 17.29999924]\n",
      " [ 17.29999924]\n",
      " [ 17.29999924]\n",
      " [ 17.29999924]\n",
      " [ 17.29999924]\n",
      " [ 22.70000076]\n",
      " [ 22.70000076]\n",
      " [ 22.70000076]\n",
      " [ 22.70000076]\n",
      " [ 22.70000076]\n",
      " [ 18.70000076]\n",
      " [ 18.70000076]\n",
      " [ 18.70000076]\n",
      " [ 18.70000076]\n",
      " [ 18.70000076]\n",
      " [ 33.20000076]\n",
      " [ 33.20000076]\n",
      " [ 33.20000076]\n",
      " [ 33.20000076]\n",
      " [ 33.20000076]\n",
      " [ 36.29999924]\n",
      " [ 36.29999924]\n",
      " [ 36.29999924]\n",
      " [ 36.29999924]\n",
      " [ 36.29999924]\n",
      " [ 25.60000038]\n",
      " [ 25.60000038]\n",
      " [ 25.60000038]\n",
      " [ 25.60000038]\n",
      " [ 25.60000038]\n",
      " [ 23.        ]\n",
      " [ 23.        ]\n",
      " [ 23.        ]\n",
      " [ 23.        ]\n",
      " [ 23.        ]\n",
      " [ 23.        ]\n",
      " [ 23.        ]\n",
      " [ 23.        ]\n",
      " [ 23.89999962]\n",
      " [ 23.89999962]\n",
      " [ 23.89999962]\n",
      " [ 23.89999962]\n",
      " [ 23.89999962]\n",
      " [ 14.39999962]\n",
      " [ 14.39999962]\n",
      " [ 14.39999962]\n",
      " [ 14.39999962]\n",
      " [ 14.39999962]\n",
      " [ 26.20000076]\n",
      " [ 26.20000076]\n",
      " [ 26.20000076]\n",
      " [ 26.20000076]\n",
      " [ 26.20000076]\n",
      " [ 26.20000076]\n",
      " [ 26.20000076]\n",
      " [ 26.20000076]\n",
      " [ 26.20000076]\n",
      " [ 26.20000076]\n",
      " [ 16.89999962]\n",
      " [ 16.89999962]\n",
      " [ 16.89999962]\n",
      " [ 16.89999962]\n",
      " [ 16.89999962]\n",
      " [ 14.69999981]\n",
      " [ 14.69999981]\n",
      " [ 14.69999981]\n",
      " [ 14.69999981]\n",
      " [ 14.69999981]\n",
      " [ 14.19999981]\n",
      " [ 14.19999981]\n",
      " [ 26.39999962]\n",
      " [ 26.39999962]\n",
      " [ 26.39999962]\n",
      " [ 26.29999924]\n",
      " [ 26.29999924]\n",
      " [ 26.29999924]\n",
      " [ 26.29999924]\n",
      " [ 26.29999924]\n",
      " [ 18.5       ]\n",
      " [ 18.5       ]\n",
      " [ 18.5       ]\n",
      " [ 18.5       ]\n",
      " [ 18.5       ]\n",
      " [ 31.        ]\n",
      " [ 31.        ]\n",
      " [ 31.        ]\n",
      " [ 31.        ]\n",
      " [ 31.        ]\n",
      " [ 22.70000076]\n",
      " [ 22.70000076]\n",
      " [ 22.70000076]\n",
      " [ 22.70000076]\n",
      " [ 22.70000076]\n",
      " [ 21.39999962]\n",
      " [ 21.39999962]\n",
      " [ 21.39999962]\n",
      " [ 21.39999962]\n",
      " [ 21.39999962]\n",
      " [ 16.89999962]\n",
      " [ 16.89999962]\n",
      " [ 16.89999962]\n",
      " [ 16.89999962]\n",
      " [ 20.29999924]\n",
      " [ 20.29999924]\n",
      " [ 20.29999924]\n",
      " [ 20.29999924]\n",
      " [ 20.29999924]\n",
      " [ 24.        ]\n",
      " [ 24.        ]\n",
      " [ 24.        ]\n",
      " [ 24.        ]\n",
      " [ 24.        ]\n",
      " [ 33.29999924]\n",
      " [ 33.29999924]\n",
      " [ 33.29999924]\n",
      " [ 33.29999924]\n",
      " [ 26.89999962]\n",
      " [ 26.89999962]\n",
      " [ 26.89999962]\n",
      " [ 26.89999962]\n",
      " [ 26.89999962]\n",
      " [ 35.40000153]\n",
      " [ 35.40000153]\n",
      " [ 35.40000153]\n",
      " [ 35.40000153]\n",
      " [ 35.40000153]\n",
      " [ 24.70000076]\n",
      " [ 24.70000076]\n",
      " [ 24.70000076]\n",
      " [ 24.70000076]\n",
      " [ 24.70000076]\n",
      " [ 26.5       ]\n",
      " [ 26.5       ]\n",
      " [ 26.5       ]\n",
      " [ 26.5       ]\n",
      " [ 26.5       ]\n",
      " [ 17.79999924]\n",
      " [ 17.79999924]\n",
      " [ 17.79999924]\n",
      " [ 17.79999924]\n",
      " [ 17.79999924]\n",
      " [ 40.5       ]\n",
      " [ 40.5       ]\n",
      " [ 40.5       ]\n",
      " [ 40.5       ]\n",
      " [ 40.5       ]\n",
      " [ 43.09999847]\n",
      " [ 43.09999847]\n",
      " [ 43.09999847]\n",
      " [ 43.09999847]\n",
      " [ 43.09999847]\n",
      " [ 29.70000076]\n",
      " [ 29.70000076]\n",
      " [ 29.70000076]\n",
      " [ 29.70000076]\n",
      " [ 48.70000076]\n",
      " [ 48.70000076]\n",
      " [ 48.70000076]\n",
      " [ 48.70000076]\n",
      " [ 48.70000076]\n",
      " [ 22.89999962]\n",
      " [ 22.89999962]\n",
      " [ 22.89999962]\n",
      " [ 22.89999962]\n",
      " [ 22.89999962]\n",
      " [ 40.79999924]\n",
      " [ 40.79999924]\n",
      " [ 40.79999924]\n",
      " [ 40.79999924]\n",
      " [ 40.79999924]\n",
      " [ 35.90000153]\n",
      " [ 35.90000153]\n",
      " [ 35.90000153]\n",
      " [ 35.90000153]\n",
      " [ 35.90000153]\n",
      " [ 35.59999847]\n",
      " [ 35.59999847]\n",
      " [ 35.59999847]\n",
      " [ 35.59999847]\n",
      " [ 35.59999847]\n",
      " [ 23.10000038]\n",
      " [ 23.10000038]\n",
      " [ 23.10000038]\n",
      " [ 23.10000038]\n",
      " [ 23.10000038]\n",
      " [ 28.29999924]\n",
      " [ 28.29999924]\n",
      " [ 28.29999924]\n",
      " [ 28.29999924]\n",
      " [ 28.29999924]\n",
      " [ 28.10000038]\n",
      " [ 28.10000038]\n",
      " [ 28.10000038]\n",
      " [ 28.10000038]\n",
      " [ 28.10000038]\n",
      " [ 29.20000076]\n",
      " [ 29.20000076]\n",
      " [ 29.20000076]\n",
      " [ 29.20000076]\n",
      " [ 29.20000076]\n",
      " [ 16.70000076]\n",
      " [ 16.70000076]\n",
      " [ 16.70000076]\n",
      " [ 15.19999981]\n",
      " [ 15.19999981]\n",
      " [ 15.19999981]\n",
      " [ 15.19999981]\n",
      " [ 15.19999981]\n",
      " [ 23.        ]\n",
      " [ 23.        ]\n",
      " [ 23.        ]\n",
      " [ 23.        ]\n",
      " [ 23.        ]\n",
      " [ 20.79999924]\n",
      " [ 20.79999924]\n",
      " [ 20.79999924]\n",
      " [ 20.79999924]\n",
      " [ 20.79999924]\n",
      " [ 23.        ]\n",
      " [ 23.        ]\n",
      " [ 23.        ]\n",
      " [ 19.20000076]\n",
      " [ 19.20000076]\n",
      " [ 26.29999924]\n",
      " [ 26.29999924]\n",
      " [ 26.29999924]\n",
      " [ 26.29999924]\n",
      " [ 26.29999924]\n",
      " [ 22.89999962]\n",
      " [ 22.89999962]\n",
      " [ 22.89999962]\n",
      " [ 22.89999962]\n",
      " [ 22.89999962]\n",
      " [ 26.89999962]\n",
      " [ 26.89999962]\n",
      " [ 26.89999962]\n",
      " [ 26.89999962]\n",
      " [ 26.89999962]\n",
      " [ 25.        ]\n",
      " [ 25.        ]\n",
      " [ 25.        ]\n",
      " [ 25.        ]\n",
      " [ 25.        ]\n",
      " [ 25.10000038]\n",
      " [ 25.10000038]\n",
      " [ 25.10000038]\n",
      " [ 25.10000038]\n",
      " [ 25.10000038]\n",
      " [ 22.29999924]\n",
      " [ 22.29999924]\n",
      " [ 22.29999924]\n",
      " [ 22.29999924]\n",
      " [ 22.29999924]\n",
      " [  8.30000019]\n",
      " [  8.30000019]\n",
      " [  8.30000019]\n",
      " [  8.30000019]\n",
      " [  8.30000019]\n",
      " [ 14.        ]\n",
      " [ 14.        ]\n",
      " [ 14.        ]\n",
      " [ 14.        ]\n",
      " [ 14.        ]\n",
      " [ 26.        ]\n",
      " [ 26.        ]\n",
      " [ 26.        ]\n",
      " [ 26.        ]\n",
      " [ 26.        ]\n",
      " [ 22.70000076]\n",
      " [ 22.70000076]\n",
      " [ 22.70000076]\n",
      " [ 22.70000076]\n",
      " [ 22.70000076]\n",
      " [ 24.20000076]\n",
      " [ 24.20000076]\n",
      " [ 24.20000076]\n",
      " [ 24.20000076]\n",
      " [ 24.20000076]\n",
      " [ 32.90000153]\n",
      " [ 32.90000153]\n",
      " [ 32.90000153]\n",
      " [ 32.90000153]\n",
      " [ 32.90000153]\n",
      " [ 32.90000153]\n",
      " [ 32.90000153]\n",
      " [ 32.90000153]\n",
      " [ 32.90000153]\n",
      " [ 15.69999981]\n",
      " [ 15.69999981]\n",
      " [ 15.69999981]\n",
      " [ 15.69999981]\n",
      " [ 15.69999981]\n",
      " [ 16.39999962]\n",
      " [ 16.39999962]\n",
      " [ 16.39999962]\n",
      " [ 16.39999962]\n",
      " [ 16.39999962]\n",
      " [ 20.39999962]\n",
      " [ 20.39999962]\n",
      " [ 20.39999962]\n",
      " [ 20.39999962]\n",
      " [ 20.39999962]\n",
      " [ 34.59999847]\n",
      " [ 34.59999847]\n",
      " [ 34.59999847]\n",
      " [ 34.59999847]\n",
      " [ 34.59999847]\n",
      " [ 15.        ]\n",
      " [ 15.        ]\n",
      " [ 15.        ]\n",
      " [ 15.        ]\n",
      " [ 15.        ]\n",
      " [  5.9000001 ]\n",
      " [  5.9000001 ]\n",
      " [  5.9000001 ]\n",
      " [  5.9000001 ]\n",
      " [  5.9000001 ]\n",
      " [ 18.89999962]\n",
      " [ 18.89999962]\n",
      " [ 18.89999962]\n",
      " [ 18.89999962]\n",
      " [ 18.89999962]\n",
      " [ 37.79999924]\n",
      " [ 37.79999924]\n",
      " [ 37.79999924]\n",
      " [ 37.79999924]\n",
      " [ 37.79999924]\n",
      " [ 17.39999962]\n",
      " [ 17.39999962]\n",
      " [ 17.39999962]\n",
      " [ 17.39999962]\n",
      " [ 17.39999962]\n",
      " [ 20.79999924]\n",
      " [ 20.79999924]\n",
      " [ 20.79999924]\n",
      " [ 20.79999924]\n",
      " [ 20.79999924]\n",
      " [ 30.29999924]\n",
      " [ 30.29999924]\n",
      " [ 30.29999924]\n",
      " [ 30.29999924]\n",
      " [ 30.29999924]\n",
      " [ 24.89999962]\n",
      " [ 24.89999962]\n",
      " [ 24.89999962]\n",
      " [ 24.89999962]\n",
      " [  7.4000001 ]\n",
      " [  7.4000001 ]\n",
      " [  7.4000001 ]\n",
      " [  7.4000001 ]\n",
      " [  7.4000001 ]\n",
      " [ 19.60000038]\n",
      " [ 19.60000038]\n",
      " [ 19.60000038]\n",
      " [ 19.60000038]\n",
      " [ 19.60000038]\n",
      " [ 22.20000076]\n",
      " [ 22.20000076]\n",
      " [ 22.20000076]\n",
      " [ 22.20000076]\n",
      " [ 22.20000076]\n",
      " [ 20.        ]\n",
      " [ 20.        ]\n",
      " [ 20.        ]\n",
      " [ 20.        ]\n",
      " [ 15.69999981]\n",
      " [ 15.69999981]\n",
      " [ 15.69999981]\n",
      " [ 15.69999981]\n",
      " [ 15.69999981]\n",
      " [ 13.80000019]\n",
      " [ 13.80000019]\n",
      " [ 13.80000019]\n",
      " [ 13.80000019]\n",
      " [ 13.80000019]\n",
      " [ 25.10000038]\n",
      " [ 25.10000038]\n",
      " [ 25.10000038]\n",
      " [ 25.10000038]\n",
      " [ 25.10000038]\n",
      " [ 10.80000019]\n",
      " [ 10.80000019]\n",
      " [ 10.80000019]\n",
      " [ 10.80000019]\n",
      " [ 10.80000019]\n",
      " [ 25.20000076]\n",
      " [ 25.20000076]\n",
      " [ 25.20000076]\n",
      " [ 25.20000076]\n",
      " [ 25.20000076]\n",
      " [ 25.20000076]\n",
      " [ 25.20000076]\n",
      " [ 25.20000076]\n",
      " [ 25.20000076]\n",
      " [ 25.20000076]\n",
      " [ 25.20000076]\n",
      " [ 25.20000076]\n",
      " [ 25.20000076]\n",
      " [ 25.20000076]\n",
      " [ 25.20000076]\n",
      " [ 25.20000076]\n",
      " [ 25.20000076]\n",
      " [ 25.20000076]\n",
      " [ 20.5       ]\n",
      " [ 20.5       ]\n",
      " [ 20.5       ]\n",
      " [ 20.5       ]\n",
      " [ 20.5       ]\n",
      " [  1.79999995]\n",
      " [  1.79999995]\n",
      " [  1.79999995]\n",
      " [  1.79999995]\n",
      " [  1.79999995]\n",
      " [ 29.89999962]\n",
      " [ 29.89999962]\n",
      " [ 29.89999962]\n",
      " [ 29.89999962]\n",
      " [ 29.89999962]\n",
      " [ 20.70000076]\n",
      " [ 20.70000076]\n",
      " [ 20.70000076]\n",
      " [ 20.70000076]\n",
      " [ 20.70000076]\n",
      " [ 20.70000076]\n",
      " [ 20.70000076]]\n"
     ]
    }
   ],
   "source": [
    "dataset_fai = read_csv('fai1.csv', header = 0, index_col=0)\n",
    "values_fai = dataset_fai.values\n",
    "#encoder = LabelEncoder()\n",
    "#values_fai[:,0] = encoder.fit_transform(values_fai[:,0])\n",
    "values_fai = values_fai.astype('float32')\n",
    "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#scaled_fai = scaler.fit_transform(values_fai)\n",
    "#reframed_fai = series_to_supervised(scaled_fai, 1, 1)\n",
    "#reframed.drop(reframed.columns[[9,10,11,12,13,14,15]], axis = 1, inplace=True)\n",
    "#print(reframed_fai.head())\n",
    "print values_fai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((673, 1, 1), (673,), (5, 1, 1), (5,))\n",
      "(array([[[ 0.56146789]],\n",
      "\n",
      "       [[ 0.50825691]],\n",
      "\n",
      "       [[ 0.51009172]],\n",
      "\n",
      "       [[ 0.50091743]],\n",
      "\n",
      "       [[ 0.48440367]]], dtype=float32), array([ 0.50825691,  0.51009172,  0.50091743,  0.48440367,  0.49541286], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "values_stock = reframed_stock.values\n",
    "n_train_hours = 673\n",
    "train_stock = values_stock[:n_train_hours, :]\n",
    "\n",
    "test_stock = values_stock[n_train_hours:, :]\n",
    "\n",
    "train_X_stock, train_y_stock = train_stock[:,:-1], train_stock[:, -1]\n",
    "\n",
    "test_stock_X, test_stock_y = test_stock[:,:-1],test_stock[:,-1]\n",
    "\n",
    "train_X_stock = train_X_stock.reshape((train_X_stock.shape[0], 1, train_X_stock.shape[1]))\n",
    "test_stock_X = test_stock_X.reshape((test_stock_X.shape[0], 1, test_stock_X.shape[1]))\n",
    "print(train_X_stock.shape, train_y_stock.shape, test_stock_X.shape, test_stock_y.shape)\n",
    "print(test_stock_X, test_stock_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"stock_input_2:0\", shape=(?, 1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "stock_input = Input(shape=(train_X_stock.shape[1], train_X_stock.shape[2]), dtype='float32', name='stock_input')\n",
    "print stock_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dense_7/BiasAdd:0\", shape=(?, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "lstm_out_stock = LSTM(32)(stock_input)\n",
    "lstm_out_stock = Dense(1)(lstm_out_stock)\n",
    "print lstm_out_stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stock_output = Dense(1, activation='linear', name='stock_output')(lstm_out_stock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((673, 1, 0), (673,), (6, 1, 0), (6,))\n",
      "(array([], shape=(6, 1, 0), dtype=float32), array([ 342.,  402.,  385.,  374.,  418.,  407.], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "#values_gap = reframed_gap.values\n",
    "#values_gap = values_gap.values\n",
    "n_train_hours = 673\n",
    "train_gap = values_gap[:n_train_hours, :]\n",
    "\n",
    "test_gap = values_gap[n_train_hours:, :]\n",
    "\n",
    "train_X_gap, train_y_gap = train_gap[:,:-1], train_gap[:, -1]\n",
    "\n",
    "test_gap_X, test_gap_y = test_gap[:,:-1],test_gap[:,-1]\n",
    "\n",
    "train_X_gap = train_X_gap.reshape((train_X_gap.shape[0], 1, train_X_gap.shape[1]))\n",
    "test_gap_X = test_gap_X.reshape((test_gap_X.shape[0], 1, test_gap_X.shape[1]))\n",
    "print(train_X_gap.shape, train_y_gap.shape, test_gap_X.shape, test_gap_y.shape)\n",
    "print(test_gap_X, test_gap_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"gap_input_7:0\", shape=(?, 673, 1), dtype=float32)\n",
      "Tensor(\"dense_7/BiasAdd:0\", shape=(?, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "gap_input = Input(shape=(train_X_gap.shape[0], train_X_gap.shape[1]),dtype='float32', name='gap_input')\n",
    "#gap_input = Input(shape=(train_X_gap.shape[1],),dtype='float32', name='gap_input')\n",
    "#gap_input = TimeDistributed(Dense(1, activation='linear'))(gap_input)\n",
    "print gap_input\n",
    "#lstm_out_stock = TimeDistributed(Dense(1, activation='linear'))(lstm_out_stock)\n",
    "print lstm_out_stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lstm_out_stock_embedding = Embedding(output_dim=512, input_dim = 10000, input_length=1)(lstm_out_stock)\n",
    "\n",
    "#print lstm_out_stock_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"embedding_5/Gather:0\", shape=(?, 2, 512), dtype=float32)\n",
      "Tensor(\"dense_8/BiasAdd:0\", shape=(?, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#merg_first = keras.layers.concatenate([lstm_out_stock_embedding, gap_input])\n",
    "merg_first = keras.layers.concatenate([lstm_out_stock, gap_input])\n",
    "merg_first = Embedding(output_dim=512, input_dim = 10000, input_length=1)(merg_first)\n",
    "\n",
    "\n",
    "print merg_first\n",
    "lstm_out_gap = LSTM(64)(merg_first)\n",
    "lstm_out_gap = LSTM(64)(merg_first)\n",
    "lstm_out_gap = Dense(1)(lstm_out_gap)\n",
    "print lstm_out_gap                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gap_output = Dense(1, activation='linear', name='gap_output')(lstm_out_gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((673, 1, 0), (673,), (6, 1, 0), (6,))\n",
      "(array([], shape=(6, 1, 0), dtype=float32), array([ 20.70000076,  20.70000076,  20.70000076,  20.70000076,\n",
      "        20.70000076,  20.70000076], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "#values_fai = reframed_fai.values\n",
    "n_train_hours = 673\n",
    "train_fai = values_fai[:n_train_hours, :]\n",
    "\n",
    "test_fai = values_fai[n_train_hours:, :]\n",
    "\n",
    "train_X_fai, train_y_fai = train_fai[:,:-1], train_fai[:, -1]\n",
    "\n",
    "test_fai_X, test_fai_y = test_fai[:,:-1],test_fai[:,-1]\n",
    "\n",
    "train_X_fai = train_X_fai.reshape((train_X_fai.shape[0], 1, train_X_fai.shape[1]))\n",
    "test_fai_X = test_fai_X.reshape((test_fai_X.shape[0], 1, test_fai_X.shape[1]))\n",
    "print(train_X_fai.shape, train_y_fai.shape, test_fai_X.shape, test_fai_y.shape)\n",
    "print(test_fai_X, test_fai_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"fai_input_2:0\", shape=(?, 1), dtype=float32)\n",
      "Tensor(\"dense_8/BiasAdd:0\", shape=(?, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#gap_input = Input(shape=(train_X_gap.shape[1],),dtype='float32', name='gap_input')\n",
    "#gap_input = TimeDistributed(Dense(1, activation='linear'))(gap_input)\n",
    "\n",
    "#lstm_out_stock = TimeDistributed(Dense(1, activation='linear'))(lstm_out_stock)\n",
    "\n",
    "fai_input = Input(shape=(train_X_fai.shape[1], ),dtype='float32', name='fai_input')\n",
    "#gap_input = TimeDistributed(Dense(1, activation='linear'))(gap_input)\n",
    "print fai_input\n",
    "print lstm_out_gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lstm_out_gap_embedding = Embedding(output_dim=512, input_dim = 10000, input_length=1)(lstm_out_gap)\n",
    "\n",
    "#print lstm_out_gap_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"embedding_6/Gather:0\", shape=(?, 2, 512), dtype=float32)\n",
      "Tensor(\"dense_9/BiasAdd:0\", shape=(?, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "merg_second = keras.layers.concatenate([lstm_out_gap, fai_input])\n",
    "merg_second = Embedding(output_dim=512, input_dim = 10000, input_length=1)(merg_second)\n",
    "\n",
    "print merg_second\n",
    "lstm_out_fai = LSTM(128)(merg_second)\n",
    "lstm_out_fai = Dense(1)(lstm_out_fai)\n",
    "#merg_second = keras.layers.concatenate([lstm_out_gap_embedding, fai_input])\n",
    "print lstm_out_fai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = Dense(64, activation='linear')(lstm_out_fai)\n",
    "\n",
    "main_output = Dense(1, activation='linear', name='main_output')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=[stock_input, gap_input, fai_input], outputs=[stock_output, gap_output, main_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss={'stock_output':'mse', 'gap_output':'mse' ,'main_output':'mse'},\n",
    "             loss_weights={'main_output': 1., 'stock_output': 0.2, 'gap_output': 0.2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected gap_input to have 2 dimensions, but got array with shape (673, 1, 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-a41ab4d15a7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m           \u001b[0;34m'gap_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_y_gap\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m           'main_output':train_y_fai},\n\u001b[0;32m---> 13\u001b[0;31m          epochs=50, batch_size=1, validation_data=validation_data, verbose=0, shuffle=False)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1520\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1521\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1522\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1523\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1524\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1376\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1378\u001b[0;31m                                     exception_prefix='input')\n\u001b[0m\u001b[1;32m   1379\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[1;32m   1380\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    130\u001b[0m                                  \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                                  \u001b[0;34m' dimensions, but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                                  str(array.shape))\n\u001b[0m\u001b[1;32m    133\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected gap_input to have 2 dimensions, but got array with shape (673, 1, 0)"
     ]
    }
   ],
   "source": [
    "validation_data=({'stock_input':test_stock_X, \n",
    "               'gap_input': test_gap_X, \n",
    "               'fai_input': test_fai_X},\n",
    "              {'stock_output':test_stock_y , \n",
    "               'gap_output': test_gap_y ,\n",
    "               'main_output':test_fai_y})\n",
    "history=model.fit({'stock_input':train_X_stock, \n",
    "           'gap_input': train_X_gap, \n",
    "           'fai_input': train_X_fai},\n",
    "         {'stock_output':train_y_stock , \n",
    "          'gap_output': train_y_gap ,\n",
    "          'main_output':train_y_fai},\n",
    "         epochs=50, batch_size=1, validation_data=validation_data, verbose=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
