{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "from numpy import newaxis, concatenate\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pandas import read_csv, DataFrame,concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_len = 1\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(),list()\n",
    "    for i in range(n_in, 0 ,-1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1,i)) for j in range(n_vars)]\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    agg = concat(cols, axis =1)\n",
    "    agg.columns = names\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace = True)\n",
    "    return agg\n",
    "\n",
    "def plot_results(predicted_data, true_data):\n",
    "    fig = plt.figure(facecolor='white')\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(true_data, label='True Data')\n",
    "    plt.plot(predicted_data, label='Prediction')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "def predict_sequences_full(model, data, window_size):\n",
    "    #Shift the window by 1 new prediction each time, re-run predictions on new window\n",
    "    curr_frame = data[0]\n",
    "    predicted = []\n",
    "    for i in range(len(data)):\n",
    "        predicted.append(model.predict(curr_frame[newaxis,:,:])[0,0])\n",
    "        curr_frame = curr_frame[1:]\n",
    "        curr_frame = np.insert(curr_frame, window_size-1,predicted[-1], axis=0)\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   var1(t-1)  var2(t-1)  var3(t-1)   var1(t)   var2(t)   var3(t)\n",
      "1   0.191304   0.590510   0.045354  0.182609  0.657293  0.042520\n",
      "2   0.182609   0.657293   0.042520  0.191304  0.578207  0.051654\n",
      "3   0.191304   0.578207   0.051654  0.182609  0.636204  0.046614\n",
      "4   0.182609   0.636204   0.046614  0.104348  0.576450  0.051969\n",
      "5   0.104348   0.576450   0.051969  0.095652  0.623902  0.046614\n",
      "   var1(t-1)   var1(t)\n",
      "1   0.157798  0.161468\n",
      "2   0.161468  0.150459\n",
      "3   0.150459  0.177982\n",
      "4   0.177982  0.166972\n",
      "5   0.166972  0.179817\n"
     ]
    }
   ],
   "source": [
    "dataset = read_csv('input2.csv', header = 0, index_col=0)\n",
    "dataset_stock = read_csv('stock1.csv', header = 0, index_col=0)\n",
    "values = dataset.values\n",
    "values_stock = dataset_stock.values\n",
    "encoder = LabelEncoder()\n",
    "values[:,0] = encoder.fit_transform(values[:,0])\n",
    "values_stock[:,0] = encoder.fit_transform(values_stock[:,0])\n",
    "values = values.astype('float32')\n",
    "values_stock = values_stock.astype('float32')\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "scaled_stock = scaler.fit_transform(values_stock)\n",
    "reframed = series_to_supervised(scaled, 1, 1)\n",
    "reframed_stock = series_to_supervised(scaled_stock, 1, 1)\n",
    "print(reframed.head())\n",
    "print(reframed_stock.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(670, 1, 5) (670,) (5, 1, 5) (5,)\n",
      "(670, 1, 1) (670,) (5, 1, 1) (5,)\n"
     ]
    }
   ],
   "source": [
    "values = reframed.values\n",
    "values_stock = reframed_stock.values\n",
    "n_train_hours = 670\n",
    "n_end = n_train_hours + 5\n",
    "train = values[:n_train_hours, :]\n",
    "train_stock = values_stock[:n_train_hours,:]\n",
    "test = values[n_train_hours:n_end :]\n",
    "test_stock = values_stock[n_train_hours:n_end:]\n",
    "train_X, train_y = train[:,:-1], train[:, -1]\n",
    "train_stock_X, train_stock_y = train_stock[:,:-1], train_stock[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:,-1]\n",
    "test_stock_X, test_stock_y = test_stock[:, :-1], test_stock[:,-1] \n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "train_stock_X = train_stock_X.reshape((train_stock_X.shape[0], 1, train_stock_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "test_stock_X = test_stock_X.reshape((test_stock_X.shape[0],1, test_stock_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "print(train_stock_X.shape, train_stock_y.shape, test_stock_X.shape, test_stock_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Compilation Time : 0.024383544921875\n",
      "Train on 670 samples, validate on 5 samples\n",
      "Epoch 1/50\n",
      "2s - loss: 0.0399 - val_loss: 0.0102\n",
      "Epoch 2/50\n",
      "2s - loss: 0.0588 - val_loss: 0.0258\n",
      "Epoch 3/50\n",
      "2s - loss: 0.0579 - val_loss: 0.0148\n",
      "Epoch 4/50\n",
      "2s - loss: 0.0653 - val_loss: 0.0116\n",
      "Epoch 5/50\n",
      "2s - loss: 0.0646 - val_loss: 0.0166\n",
      "Epoch 6/50\n",
      "2s - loss: 0.0668 - val_loss: 0.0146\n",
      "Epoch 7/50\n",
      "2s - loss: 0.0677 - val_loss: 0.0064\n",
      "Epoch 8/50\n",
      "2s - loss: 0.0653 - val_loss: 0.0065\n",
      "Epoch 9/50\n",
      "2s - loss: 0.0626 - val_loss: 0.0051\n",
      "Epoch 10/50\n",
      "2s - loss: 0.0625 - val_loss: 0.0089\n",
      "Epoch 11/50\n",
      "2s - loss: 0.0578 - val_loss: 0.0081\n",
      "Epoch 12/50\n",
      "2s - loss: 0.0550 - val_loss: 0.0117\n",
      "Epoch 13/50\n",
      "2s - loss: 0.0554 - val_loss: 0.0153\n",
      "Epoch 14/50\n",
      "2s - loss: 0.0504 - val_loss: 0.0132\n",
      "Epoch 15/50\n",
      "2s - loss: 0.0533 - val_loss: 0.0242\n",
      "Epoch 16/50\n",
      "2s - loss: 0.0462 - val_loss: 0.0176\n",
      "Epoch 17/50\n",
      "2s - loss: 0.0462 - val_loss: 0.0148\n",
      "Epoch 18/50\n",
      "2s - loss: 0.0456 - val_loss: 0.0111\n",
      "Epoch 19/50\n",
      "2s - loss: 0.0410 - val_loss: 0.0153\n",
      "Epoch 20/50\n",
      "2s - loss: 0.0426 - val_loss: 0.0267\n",
      "Epoch 21/50\n",
      "2s - loss: 0.0386 - val_loss: 0.0124\n",
      "Epoch 22/50\n",
      "2s - loss: 0.0371 - val_loss: 0.0224\n",
      "Epoch 23/50\n",
      "2s - loss: 0.0388 - val_loss: 0.0156\n",
      "Epoch 24/50\n",
      "2s - loss: 0.0357 - val_loss: 0.0031\n",
      "Epoch 25/50\n",
      "2s - loss: 0.0368 - val_loss: 0.0167\n",
      "Epoch 26/50\n",
      "2s - loss: 0.0356 - val_loss: 0.0152\n",
      "Epoch 27/50\n",
      "2s - loss: 0.0375 - val_loss: 0.0138\n",
      "Epoch 28/50\n",
      "2s - loss: 0.0356 - val_loss: 0.0093\n",
      "Epoch 29/50\n",
      "2s - loss: 0.0330 - val_loss: 0.0027\n",
      "Epoch 30/50\n",
      "2s - loss: 0.0327 - val_loss: 0.0222\n",
      "Epoch 31/50\n",
      "2s - loss: 0.0358 - val_loss: 0.0022\n",
      "Epoch 32/50\n",
      "2s - loss: 0.0313 - val_loss: 0.0076\n",
      "Epoch 33/50\n",
      "2s - loss: 0.0330 - val_loss: 0.0043\n",
      "Epoch 34/50\n",
      "2s - loss: 0.0317 - val_loss: 0.0092\n",
      "Epoch 35/50\n",
      "2s - loss: 0.0302 - val_loss: 0.0027\n",
      "Epoch 36/50\n",
      "2s - loss: 0.0276 - val_loss: 0.0127\n",
      "Epoch 37/50\n",
      "3s - loss: 0.0286 - val_loss: 0.0136\n",
      "Epoch 38/50\n",
      "3s - loss: 0.0315 - val_loss: 0.0102\n",
      "Epoch 39/50\n",
      "4s - loss: 0.0268 - val_loss: 0.0081\n",
      "Epoch 40/50\n",
      "4s - loss: 0.0310 - val_loss: 0.0055\n",
      "Epoch 41/50\n",
      "5s - loss: 0.0286 - val_loss: 0.0059\n",
      "Epoch 42/50\n",
      "4s - loss: 0.0326 - val_loss: 0.0031\n",
      "Epoch 43/50\n",
      "4s - loss: 0.0282 - val_loss: 0.0034\n",
      "Epoch 44/50\n",
      "4s - loss: 0.0276 - val_loss: 0.0091\n",
      "Epoch 45/50\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(20, input_shape=(train_X.shape[1], train_X.shape[2]),return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100,return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation(\"linear\"))\n",
    "start = time.time()\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "print(\"> Compilation Time :\", time.time() - start)\n",
    "history = model.fit(train_X, train_y, epochs=50, batch_size=1, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "#print (seq_len)\n",
    "predicted = predict_sequences_full(model, test_X, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print (predicted)\n",
    "l = len(predicted)\n",
    "print (l)\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = np.reshape(predicted, (l,))\n",
    "\n",
    "print(predicted, test_stock_y)\n",
    "score = mean_squared_error(predicted, test_stock_y)\n",
    "    \n",
    "print(\"MSE: %f\" % score)\n",
    "plot_results(predicted, test_stock_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
