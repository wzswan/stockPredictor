{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import keras\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import newaxis\n",
    "from keras.layers.core import  Activation, Dropout\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding,LSTM, Dense,TimeDistributed, Reshape\n",
    "from keras import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "#from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(),list()\n",
    "    for i in range(n_in, 0 ,-1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1,i)) for j in range(n_vars)]\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    agg = concat(cols, axis =1)\n",
    "    agg.columns = names\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace = True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   var1(t-1)   var1(t)\n",
      "1   0.157798  0.161468\n",
      "2   0.161468  0.150459\n",
      "3   0.150459  0.177982\n",
      "4   0.177982  0.166972\n",
      "5   0.166972  0.179817\n"
     ]
    }
   ],
   "source": [
    "dataset_stock = read_csv('stock1.csv', header = 0, index_col=0)\n",
    "values_stock = dataset_stock.values\n",
    "encoder = LabelEncoder()\n",
    "values_stock[:,0] = encoder.fit_transform(values_stock[:,0])\n",
    "values_stock = values_stock.astype('float32')\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_stock = scaler.fit_transform(values_stock)\n",
    "reframed_stock = series_to_supervised(scaled_stock, 1, 1)\n",
    "print(reframed_stock.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   var1(t-1)   var1(t)\n",
      "1   0.488038  0.435407\n",
      "2   0.435407  0.617225\n",
      "3   0.617225  0.401914\n",
      "4   0.401914  0.559809\n",
      "5   0.559809  0.397129\n"
     ]
    }
   ],
   "source": [
    "dataset_gap = read_csv('gap1.csv', header = 0, index_col=0)\n",
    "values_gap = dataset_gap.values\n",
    "encoder = LabelEncoder()\n",
    "values_gap[:,0] = encoder.fit_transform(values_gap[:,0])\n",
    "values_gap = values_gap.astype('float32')\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_gap = scaler.fit_transform(values_gap)\n",
    "reframed_gap = series_to_supervised(scaled_gap, 1, 1)\n",
    "\n",
    "print(reframed_gap.head())\n",
    "#print values_gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   var1(t-1)   var1(t)\n",
      "1   0.182609  0.191304\n",
      "2   0.191304  0.182609\n",
      "3   0.182609  0.191304\n",
      "4   0.191304  0.182609\n",
      "5   0.182609  0.104348\n"
     ]
    }
   ],
   "source": [
    "dataset_fai = read_csv('fai1.csv', header = 0, index_col=0)\n",
    "values_fai = dataset_fai.values\n",
    "encoder = LabelEncoder()\n",
    "values_fai[:,0] = encoder.fit_transform(values_fai[:,0])\n",
    "values_fai = values_fai.astype('float32')\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_fai = scaler.fit_transform(values_fai)\n",
    "reframed_fai = series_to_supervised(scaled_fai, 1, 1)\n",
    "#reframed.drop(reframed.columns[[9,10,11,12,13,14,15]], axis = 1, inplace=True)\n",
    "print(reframed_fai.head())\n",
    "#print values_fai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((673, 1, 1), (673,), (5, 1, 1), (5,))\n",
      "(array([[[ 0.56146789]],\n",
      "\n",
      "       [[ 0.50825691]],\n",
      "\n",
      "       [[ 0.51009172]],\n",
      "\n",
      "       [[ 0.50091743]],\n",
      "\n",
      "       [[ 0.48440367]]], dtype=float32), array([ 0.50825691,  0.51009172,  0.50091743,  0.48440367,  0.49541286], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "values_stock = reframed_stock.values\n",
    "n_train_hours = 673\n",
    "train_stock = values_stock[:n_train_hours, :]\n",
    "\n",
    "test_stock = values_stock[n_train_hours:, :]\n",
    "\n",
    "train_X_stock, train_y_stock = train_stock[:,:-1], train_stock[:, -1]\n",
    "\n",
    "test_stock_X, test_stock_y = test_stock[:,:-1],test_stock[:,-1]\n",
    "\n",
    "train_X_stock = train_X_stock.reshape((train_X_stock.shape[0], 1, train_X_stock.shape[1]))\n",
    "test_stock_X = test_stock_X.reshape((test_stock_X.shape[0], 1, test_stock_X.shape[1]))\n",
    "print(train_X_stock.shape, train_y_stock.shape, test_stock_X.shape, test_stock_y.shape)\n",
    "print(test_stock_X, test_stock_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"stock_input_5:0\", shape=(?, 1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "stock_input = Input(shape=(train_X_stock.shape[1], train_X_stock.shape[2]), dtype='float32', name='stock_input')\n",
    "#stock_input = Embedding(output_dim=512, input_dim = 10000, input_length=1)(stock_input)\n",
    "\n",
    "#print lstm_out_stock_embedding\n",
    "print stock_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"reshape_7/Reshape:0\", shape=(?, 1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "lstm_out_stock = LSTM(32)(stock_input)\n",
    "lstm_out_stock_cut = Dense(1)(lstm_out_stock)\n",
    "lstm_out_stock = Reshape((1,1))(lstm_out_stock_cut)\n",
    "print lstm_out_stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stock_output = Dense(1, activation='linear', name='stock_output')(lstm_out_stock_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((673, 1, 1), (673,), (5, 1, 1), (5,))\n",
      "(array([[[ 0.22009568]],\n",
      "\n",
      "       [[ 0.48803827]],\n",
      "\n",
      "       [[ 0.40669855]],\n",
      "\n",
      "       [[ 0.35406697]],\n",
      "\n",
      "       [[ 0.56459326]]], dtype=float32), array([ 0.48803827,  0.40669855,  0.35406697,  0.56459326,  0.5119617 ], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "values_gap = reframed_gap.values\n",
    "\n",
    "n_train_hours = 673\n",
    "train_gap = values_gap[:n_train_hours, :]\n",
    "\n",
    "test_gap = values_gap[n_train_hours:, :]\n",
    "\n",
    "train_X_gap, train_y_gap = train_gap[:,:-1], train_gap[:, -1]\n",
    "\n",
    "test_gap_X, test_gap_y = test_gap[:,:-1],test_gap[:,-1]\n",
    "\n",
    "train_X_gap = train_X_gap.reshape((train_X_gap.shape[0], 1, train_X_gap.shape[1]))\n",
    "test_gap_X = test_gap_X.reshape((test_gap_X.shape[0], 1, test_gap_X.shape[1]))\n",
    "print(train_X_gap.shape, train_y_gap.shape, test_gap_X.shape, test_gap_y.shape)\n",
    "print(test_gap_X, test_gap_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"gap_input_2:0\", shape=(?, 1, 1), dtype=float32)\n",
      "Tensor(\"reshape_7/Reshape:0\", shape=(?, 1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "gap_input = Input(shape=(train_X_gap.shape[1], train_X_gap.shape[2]),dtype='float32', name='gap_input')\n",
    "print gap_input\n",
    "print lstm_out_stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"concatenate_5/concat:0\", shape=(?, 1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#merg_first = keras.layers.concatenate([lstm_out_stock_embedding, gap_input])\n",
    "merg_first = keras.layers.concatenate([lstm_out_stock, gap_input])\n",
    "print merg_first "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"reshape_8/Reshape:0\", shape=(?, 1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#merg_first = Embedding(output_dim=512, input_dim = 10000, input_length=1)(merg_first)\n",
    "#print merg_first\n",
    "lstm_out_gap = LSTM(64)(merg_first)\n",
    "lstm_out_gap = LSTM(64)(merg_first)\n",
    "lstm_out_gap_cut = Dense(1)(lstm_out_gap)\n",
    "lstm_out_gap = Reshape((1,1))(lstm_out_gap_cut)\n",
    "print lstm_out_gap   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gap_output = Dense(1, activation='linear', name='gap_output')(lstm_out_gap_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((673, 1, 1), (673,), (5, 1, 1), (5,))\n",
      "(array([[[ 0.58260864]],\n",
      "\n",
      "       [[ 0.58260864]],\n",
      "\n",
      "       [[ 0.58260864]],\n",
      "\n",
      "       [[ 0.58260864]],\n",
      "\n",
      "       [[ 0.58260864]]], dtype=float32), array([ 0.58260864,  0.58260864,  0.58260864,  0.58260864,  0.58260864], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "values_fai = reframed_fai.values\n",
    "n_train_hours = 673\n",
    "train_fai = values_fai[:n_train_hours, :]\n",
    "\n",
    "test_fai = values_fai[n_train_hours:, :]\n",
    "\n",
    "train_X_fai, train_y_fai = train_fai[:,:-1], train_fai[:, -1]\n",
    "\n",
    "test_fai_X, test_fai_y = test_fai[:,:-1],test_fai[:,-1]\n",
    "\n",
    "train_X_fai = train_X_fai.reshape((train_X_fai.shape[0], 1, train_X_fai.shape[1]))\n",
    "test_fai_X = test_fai_X.reshape((test_fai_X.shape[0], 1, test_fai_X.shape[1]))\n",
    "print(train_X_fai.shape, train_y_fai.shape, test_fai_X.shape, test_fai_y.shape)\n",
    "print(test_fai_X, test_fai_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"fai_input_2:0\", shape=(?, 1, 1), dtype=float32)\n",
      "Tensor(\"reshape_8/Reshape:0\", shape=(?, 1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "fai_input = Input(shape=(train_X_fai.shape[1], train_X_fai.shape[2]),dtype='float32', name='fai_input')\n",
    "print fai_input\n",
    "print lstm_out_gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"concatenate_6/concat:0\", shape=(?, 1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "merg_second = keras.layers.concatenate([lstm_out_gap, fai_input])\n",
    "print merg_second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dense_15/BiasAdd:0\", shape=(?, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "lstm_out_fai = LSTM(128)(merg_second)\n",
    "lstm_out_fai = Dense(1)(lstm_out_fai)\n",
    "#lstm_out_fai = Reshape((1,1))(lstm_out_fai)\n",
    "print lstm_out_fai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = Dense(64, activation='linear')(lstm_out_fai)\n",
    "\n",
    "main_output = Dense(1, activation='linear', name='main_output')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=[stock_input, gap_input, fai_input], outputs=[stock_output, gap_output, main_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss={'stock_output':'mse', 'gap_output':'mse' ,'main_output':'mse'},\n",
    "             loss_weights={'main_output': 1., 'stock_output': 0.2, 'gap_output': 0.2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 673 samples, validate on 5 samples\n",
      "Epoch 1/50\n",
      "4s - loss: 0.0312 - stock_output_loss: 0.0015 - gap_output_loss: 0.0480 - main_output_loss: 0.0214 - val_loss: 0.0020 - val_stock_output_loss: 6.3108e-04 - val_gap_output_loss: 0.0060 - val_main_output_loss: 6.6913e-04\n",
      "Epoch 2/50\n",
      "3s - loss: 0.0267 - stock_output_loss: 0.0015 - gap_output_loss: 0.0414 - main_output_loss: 0.0181 - val_loss: 0.0021 - val_stock_output_loss: 9.2469e-04 - val_gap_output_loss: 0.0058 - val_main_output_loss: 7.9008e-04\n",
      "Epoch 3/50\n",
      "3s - loss: 0.0265 - stock_output_loss: 0.0014 - gap_output_loss: 0.0406 - main_output_loss: 0.0181 - val_loss: 0.0022 - val_stock_output_loss: 0.0014 - val_gap_output_loss: 0.0056 - val_main_output_loss: 7.7981e-04\n",
      "Epoch 4/50\n",
      "3s - loss: 0.0264 - stock_output_loss: 0.0014 - gap_output_loss: 0.0402 - main_output_loss: 0.0181 - val_loss: 0.0021 - val_stock_output_loss: 0.0013 - val_gap_output_loss: 0.0056 - val_main_output_loss: 7.4854e-04\n",
      "Epoch 5/50\n",
      "3s - loss: 0.0263 - stock_output_loss: 0.0013 - gap_output_loss: 0.0399 - main_output_loss: 0.0180 - val_loss: 0.0021 - val_stock_output_loss: 0.0012 - val_gap_output_loss: 0.0055 - val_main_output_loss: 7.0740e-04\n",
      "Epoch 6/50\n",
      "3s - loss: 0.0263 - stock_output_loss: 0.0013 - gap_output_loss: 0.0399 - main_output_loss: 0.0180 - val_loss: 0.0020 - val_stock_output_loss: 0.0012 - val_gap_output_loss: 0.0056 - val_main_output_loss: 6.8223e-04\n",
      "Epoch 7/50\n",
      "3s - loss: 0.0263 - stock_output_loss: 0.0013 - gap_output_loss: 0.0400 - main_output_loss: 0.0180 - val_loss: 0.0020 - val_stock_output_loss: 0.0011 - val_gap_output_loss: 0.0056 - val_main_output_loss: 6.3654e-04\n",
      "Epoch 8/50\n",
      "3s - loss: 0.0263 - stock_output_loss: 0.0013 - gap_output_loss: 0.0401 - main_output_loss: 0.0180 - val_loss: 0.0019 - val_stock_output_loss: 0.0011 - val_gap_output_loss: 0.0056 - val_main_output_loss: 5.9566e-04\n",
      "Epoch 9/50\n",
      "3s - loss: 0.0263 - stock_output_loss: 0.0013 - gap_output_loss: 0.0402 - main_output_loss: 0.0180 - val_loss: 0.0019 - val_stock_output_loss: 0.0011 - val_gap_output_loss: 0.0057 - val_main_output_loss: 5.5975e-04\n",
      "Epoch 10/50\n",
      "3s - loss: 0.0263 - stock_output_loss: 0.0013 - gap_output_loss: 0.0403 - main_output_loss: 0.0180 - val_loss: 0.0019 - val_stock_output_loss: 0.0011 - val_gap_output_loss: 0.0057 - val_main_output_loss: 5.2164e-04\n",
      "Epoch 11/50\n",
      "3s - loss: 0.0263 - stock_output_loss: 0.0013 - gap_output_loss: 0.0403 - main_output_loss: 0.0180 - val_loss: 0.0018 - val_stock_output_loss: 0.0010 - val_gap_output_loss: 0.0057 - val_main_output_loss: 4.9490e-04\n",
      "Epoch 12/50\n",
      "3s - loss: 0.0263 - stock_output_loss: 0.0013 - gap_output_loss: 0.0403 - main_output_loss: 0.0180 - val_loss: 0.0018 - val_stock_output_loss: 0.0010 - val_gap_output_loss: 0.0057 - val_main_output_loss: 4.6438e-04\n",
      "Epoch 13/50\n",
      "3s - loss: 0.0263 - stock_output_loss: 0.0013 - gap_output_loss: 0.0403 - main_output_loss: 0.0180 - val_loss: 0.0018 - val_stock_output_loss: 0.0010 - val_gap_output_loss: 0.0057 - val_main_output_loss: 4.3165e-04\n",
      "Epoch 14/50\n",
      "3s - loss: 0.0263 - stock_output_loss: 0.0013 - gap_output_loss: 0.0403 - main_output_loss: 0.0180 - val_loss: 0.0017 - val_stock_output_loss: 0.0010 - val_gap_output_loss: 0.0057 - val_main_output_loss: 3.8702e-04\n",
      "Epoch 15/50\n",
      "3s - loss: 0.0263 - stock_output_loss: 0.0013 - gap_output_loss: 0.0402 - main_output_loss: 0.0180 - val_loss: 0.0017 - val_stock_output_loss: 9.9933e-04 - val_gap_output_loss: 0.0058 - val_main_output_loss: 3.6226e-04\n",
      "Epoch 16/50\n",
      "3s - loss: 0.0263 - stock_output_loss: 0.0013 - gap_output_loss: 0.0402 - main_output_loss: 0.0180 - val_loss: 0.0017 - val_stock_output_loss: 9.8284e-04 - val_gap_output_loss: 0.0058 - val_main_output_loss: 3.0992e-04\n",
      "Epoch 17/50\n",
      "3s - loss: 0.0263 - stock_output_loss: 0.0013 - gap_output_loss: 0.0402 - main_output_loss: 0.0180 - val_loss: 0.0016 - val_stock_output_loss: 9.8477e-04 - val_gap_output_loss: 0.0058 - val_main_output_loss: 2.9156e-04\n",
      "Epoch 18/50\n",
      "3s - loss: 0.0263 - stock_output_loss: 0.0013 - gap_output_loss: 0.0402 - main_output_loss: 0.0180 - val_loss: 0.0016 - val_stock_output_loss: 9.7489e-04 - val_gap_output_loss: 0.0058 - val_main_output_loss: 2.5584e-04\n",
      "Epoch 19/50\n",
      "3s - loss: 0.0263 - stock_output_loss: 0.0012 - gap_output_loss: 0.0401 - main_output_loss: 0.0180 - val_loss: 0.0016 - val_stock_output_loss: 9.5204e-04 - val_gap_output_loss: 0.0058 - val_main_output_loss: 2.2352e-04\n",
      "Epoch 20/50\n",
      "3s - loss: 0.0263 - stock_output_loss: 0.0012 - gap_output_loss: 0.0401 - main_output_loss: 0.0180 - val_loss: 0.0015 - val_stock_output_loss: 9.4939e-04 - val_gap_output_loss: 0.0058 - val_main_output_loss: 1.9547e-04\n",
      "Epoch 21/50\n",
      "3s - loss: 0.0263 - stock_output_loss: 0.0012 - gap_output_loss: 0.0401 - main_output_loss: 0.0181 - val_loss: 0.0015 - val_stock_output_loss: 9.2829e-04 - val_gap_output_loss: 0.0058 - val_main_output_loss: 1.6767e-04\n",
      "Epoch 22/50\n",
      "3s - loss: 0.0263 - stock_output_loss: 0.0012 - gap_output_loss: 0.0401 - main_output_loss: 0.0181 - val_loss: 0.0015 - val_stock_output_loss: 9.2577e-04 - val_gap_output_loss: 0.0058 - val_main_output_loss: 1.4650e-04\n",
      "Epoch 23/50\n",
      "3s - loss: 0.0263 - stock_output_loss: 0.0012 - gap_output_loss: 0.0401 - main_output_loss: 0.0181 - val_loss: 0.0015 - val_stock_output_loss: 9.1873e-04 - val_gap_output_loss: 0.0058 - val_main_output_loss: 1.2725e-04\n",
      "Epoch 24/50\n",
      "3s - loss: 0.0263 - stock_output_loss: 0.0012 - gap_output_loss: 0.0401 - main_output_loss: 0.0181 - val_loss: 0.0015 - val_stock_output_loss: 9.0973e-04 - val_gap_output_loss: 0.0058 - val_main_output_loss: 1.0664e-04\n",
      "Epoch 25/50\n",
      "3s - loss: 0.0263 - stock_output_loss: 0.0012 - gap_output_loss: 0.0401 - main_output_loss: 0.0181 - val_loss: 0.0014 - val_stock_output_loss: 9.0289e-04 - val_gap_output_loss: 0.0059 - val_main_output_loss: 8.6351e-05\n",
      "Epoch 26/50\n",
      "3s - loss: 0.0263 - stock_output_loss: 0.0012 - gap_output_loss: 0.0401 - main_output_loss: 0.0181 - val_loss: 0.0014 - val_stock_output_loss: 9.0969e-04 - val_gap_output_loss: 0.0058 - val_main_output_loss: 8.0351e-05\n",
      "Epoch 27/50\n",
      "3s - loss: 0.0263 - stock_output_loss: 0.0012 - gap_output_loss: 0.0401 - main_output_loss: 0.0181 - val_loss: 0.0014 - val_stock_output_loss: 9.0765e-04 - val_gap_output_loss: 0.0059 - val_main_output_loss: 6.0400e-05\n",
      "Epoch 28/50\n",
      "3s - loss: 0.0263 - stock_output_loss: 0.0012 - gap_output_loss: 0.0401 - main_output_loss: 0.0181 - val_loss: 0.0014 - val_stock_output_loss: 9.1767e-04 - val_gap_output_loss: 0.0059 - val_main_output_loss: 5.0849e-05\n",
      "Epoch 29/50\n",
      "3s - loss: 0.0264 - stock_output_loss: 0.0012 - gap_output_loss: 0.0401 - main_output_loss: 0.0181 - val_loss: 0.0014 - val_stock_output_loss: 9.1662e-04 - val_gap_output_loss: 0.0059 - val_main_output_loss: 4.4481e-05\n",
      "Epoch 30/50\n",
      "3s - loss: 0.0264 - stock_output_loss: 0.0012 - gap_output_loss: 0.0401 - main_output_loss: 0.0181 - val_loss: 0.0014 - val_stock_output_loss: 9.2600e-04 - val_gap_output_loss: 0.0059 - val_main_output_loss: 3.6191e-05\n",
      "Epoch 31/50\n",
      "3s - loss: 0.0264 - stock_output_loss: 0.0012 - gap_output_loss: 0.0401 - main_output_loss: 0.0181 - val_loss: 0.0014 - val_stock_output_loss: 9.4231e-04 - val_gap_output_loss: 0.0059 - val_main_output_loss: 3.2741e-05\n",
      "Epoch 32/50\n",
      "3s - loss: 0.0264 - stock_output_loss: 0.0012 - gap_output_loss: 0.0401 - main_output_loss: 0.0181 - val_loss: 0.0014 - val_stock_output_loss: 9.5108e-04 - val_gap_output_loss: 0.0059 - val_main_output_loss: 2.8984e-05\n",
      "Epoch 33/50\n",
      "3s - loss: 0.0264 - stock_output_loss: 0.0012 - gap_output_loss: 0.0401 - main_output_loss: 0.0181 - val_loss: 0.0014 - val_stock_output_loss: 9.6212e-04 - val_gap_output_loss: 0.0059 - val_main_output_loss: 2.1489e-05\n",
      "Epoch 34/50\n",
      "3s - loss: 0.0264 - stock_output_loss: 0.0012 - gap_output_loss: 0.0401 - main_output_loss: 0.0181 - val_loss: 0.0014 - val_stock_output_loss: 9.7878e-04 - val_gap_output_loss: 0.0059 - val_main_output_loss: 1.8780e-05\n",
      "Epoch 35/50\n",
      "3s - loss: 0.0264 - stock_output_loss: 0.0012 - gap_output_loss: 0.0401 - main_output_loss: 0.0181 - val_loss: 0.0014 - val_stock_output_loss: 9.8596e-04 - val_gap_output_loss: 0.0059 - val_main_output_loss: 1.4451e-05\n",
      "Epoch 36/50\n",
      "3s - loss: 0.0264 - stock_output_loss: 0.0012 - gap_output_loss: 0.0401 - main_output_loss: 0.0181 - val_loss: 0.0014 - val_stock_output_loss: 0.0010 - val_gap_output_loss: 0.0059 - val_main_output_loss: 1.4952e-05\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3s - loss: 0.0264 - stock_output_loss: 0.0012 - gap_output_loss: 0.0401 - main_output_loss: 0.0181 - val_loss: 0.0014 - val_stock_output_loss: 0.0011 - val_gap_output_loss: 0.0059 - val_main_output_loss: 1.1630e-05\n",
      "Epoch 38/50\n",
      "3s - loss: 0.0264 - stock_output_loss: 0.0012 - gap_output_loss: 0.0401 - main_output_loss: 0.0181 - val_loss: 0.0014 - val_stock_output_loss: 0.0011 - val_gap_output_loss: 0.0059 - val_main_output_loss: 1.0137e-05\n",
      "Epoch 39/50\n",
      "3s - loss: 0.0264 - stock_output_loss: 0.0012 - gap_output_loss: 0.0401 - main_output_loss: 0.0182 - val_loss: 0.0014 - val_stock_output_loss: 0.0011 - val_gap_output_loss: 0.0059 - val_main_output_loss: 6.7849e-06\n",
      "Epoch 40/50\n",
      "3s - loss: 0.0264 - stock_output_loss: 0.0012 - gap_output_loss: 0.0401 - main_output_loss: 0.0182 - val_loss: 0.0014 - val_stock_output_loss: 0.0011 - val_gap_output_loss: 0.0059 - val_main_output_loss: 5.3014e-06\n",
      "Epoch 41/50\n",
      "3s - loss: 0.0264 - stock_output_loss: 0.0013 - gap_output_loss: 0.0401 - main_output_loss: 0.0182 - val_loss: 0.0014 - val_stock_output_loss: 0.0010 - val_gap_output_loss: 0.0059 - val_main_output_loss: 4.0797e-06\n",
      "Epoch 42/50\n",
      "3s - loss: 0.0264 - stock_output_loss: 0.0013 - gap_output_loss: 0.0401 - main_output_loss: 0.0182 - val_loss: 0.0014 - val_stock_output_loss: 9.8907e-04 - val_gap_output_loss: 0.0059 - val_main_output_loss: 2.4816e-06\n",
      "Epoch 43/50\n",
      "3s - loss: 0.0265 - stock_output_loss: 0.0013 - gap_output_loss: 0.0401 - main_output_loss: 0.0182 - val_loss: 0.0014 - val_stock_output_loss: 9.4872e-04 - val_gap_output_loss: 0.0059 - val_main_output_loss: 1.4965e-06\n",
      "Epoch 44/50\n",
      "3s - loss: 0.0265 - stock_output_loss: 0.0013 - gap_output_loss: 0.0401 - main_output_loss: 0.0182 - val_loss: 0.0014 - val_stock_output_loss: 9.2195e-04 - val_gap_output_loss: 0.0059 - val_main_output_loss: 1.1921e-06\n",
      "Epoch 45/50\n",
      "3s - loss: 0.0265 - stock_output_loss: 0.0014 - gap_output_loss: 0.0401 - main_output_loss: 0.0182 - val_loss: 0.0014 - val_stock_output_loss: 9.1311e-04 - val_gap_output_loss: 0.0059 - val_main_output_loss: 1.2921e-06\n",
      "Epoch 46/50\n",
      "3s - loss: 0.0265 - stock_output_loss: 0.0014 - gap_output_loss: 0.0402 - main_output_loss: 0.0182 - val_loss: 0.0014 - val_stock_output_loss: 8.9512e-04 - val_gap_output_loss: 0.0058 - val_main_output_loss: 1.4145e-06\n",
      "Epoch 47/50\n",
      "3s - loss: 0.0265 - stock_output_loss: 0.0014 - gap_output_loss: 0.0402 - main_output_loss: 0.0182 - val_loss: 0.0013 - val_stock_output_loss: 8.7307e-04 - val_gap_output_loss: 0.0058 - val_main_output_loss: 1.9057e-06\n",
      "Epoch 48/50\n",
      "3s - loss: 0.0265 - stock_output_loss: 0.0014 - gap_output_loss: 0.0402 - main_output_loss: 0.0182 - val_loss: 0.0013 - val_stock_output_loss: 8.6063e-04 - val_gap_output_loss: 0.0059 - val_main_output_loss: 4.4051e-06\n",
      "Epoch 49/50\n",
      "3s - loss: 0.0265 - stock_output_loss: 0.0014 - gap_output_loss: 0.0402 - main_output_loss: 0.0182 - val_loss: 0.0013 - val_stock_output_loss: 8.5649e-04 - val_gap_output_loss: 0.0059 - val_main_output_loss: 5.6431e-06\n",
      "Epoch 50/50\n",
      "3s - loss: 0.0265 - stock_output_loss: 0.0014 - gap_output_loss: 0.0402 - main_output_loss: 0.0182 - val_loss: 0.0013 - val_stock_output_loss: 8.4624e-04 - val_gap_output_loss: 0.0058 - val_main_output_loss: 8.3169e-06\n"
     ]
    }
   ],
   "source": [
    "validation_data=({'stock_input':test_stock_X, \n",
    "               'gap_input': test_gap_X, \n",
    "               'fai_input': test_fai_X},\n",
    "              {'stock_output':test_stock_y , \n",
    "               'gap_output': test_gap_y ,\n",
    "               'main_output':test_fai_y})\n",
    "history=model.fit({'stock_input':train_X_stock, \n",
    "           'gap_input': train_X_gap, \n",
    "           'fai_input': train_X_fai},\n",
    "         {'stock_output':train_y_stock , \n",
    "          'gap_output': train_y_gap ,\n",
    "          'main_output':train_y_fai},\n",
    "         epochs=50, batch_size=1, validation_data=validation_data, verbose=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmVniQDAzM8CBYGZmiQPBzMwA+P+xyVivah4oNAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f05c3b1db10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.56146789]]\n",
      "\n",
      " [[ 0.50825691]]\n",
      "\n",
      " [[ 0.51009172]]\n",
      "\n",
      " [[ 0.50091743]]\n",
      "\n",
      " [[ 0.48440367]]] [[[ 0.22009568]]\n",
      "\n",
      " [[ 0.48803827]]\n",
      "\n",
      " [[ 0.40669855]]\n",
      "\n",
      " [[ 0.35406697]]\n",
      "\n",
      " [[ 0.56459326]]] [[[ 0.58260864]]\n",
      "\n",
      " [[ 0.58260864]]\n",
      "\n",
      " [[ 0.58260864]]\n",
      "\n",
      " [[ 0.58260864]]\n",
      "\n",
      " [[ 0.58260864]]]\n",
      "1/5 [=====>........................] - ETA: 1s[[ 0.56146789]\n",
      " [ 0.50825691]\n",
      " [ 0.51009172]\n",
      " [ 0.50091743]\n",
      " [ 0.48440367]] [[ 0.22009568]\n",
      " [ 0.48803827]\n",
      " [ 0.40669855]\n",
      " [ 0.35406697]\n",
      " [ 0.56459326]] [[ 0.58260864]\n",
      " [ 0.58260864]\n",
      " [ 0.58260864]\n",
      " [ 0.58260864]\n",
      " [ 0.58260864]]\n"
     ]
    }
   ],
   "source": [
    "print test_stock_X, test_gap_X, test_fai_X\n",
    "yhat =  model.predict([test_stock_X, test_gap_X, test_fai_X],batch_size=1,verbose=1)\n",
    "test_stock_X = test_stock_X.reshape((test_stock_X.shape[0], test_stock_X.shape[2]))\n",
    "test_gap_X = test_gap_X.reshape((test_gap_X.shape[0], test_gap_X.shape[2]))\n",
    "test_fai_X = test_fai_X.reshape((test_fai_X.shape[0], test_fai_X.shape[2]))\n",
    "print test_stock_X, test_gap_X, test_fai_X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 15 into shape (5,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-8cc4d08afc4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#yhat = yhat.reshape((len(test_stock_y), 1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myhat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_stock_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0myhat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#print [test_stock_X,test_gap_X, test_fai_X]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 15 into shape (5,1)"
     ]
    }
   ],
   "source": [
    "#print yhat\n",
    "print len(test_stock_y)\n",
    "#yhat = yhat.reshape((len(test_stock_y), 1))\n",
    "yhat = np.array(yhat)\n",
    "yhat = yhat.reshape((len(test_stock_y), 1))\n",
    "print yhat.shape\n",
    "#print [test_stock_X,test_gap_X, test_fai_X]\n",
    "#print [test_stock_X[:,1:],test_gap_X[:,1:], test_fai_X[:,1:]]\n",
    "#test_stock_X_p = test_stock_X[0:].reshape(-1, 1)\n",
    "#test_gap_X_p = test_gap_X[0:].reshape(-1, 1)\n",
    "#test_fai_X_p = test_fai_X[0:].reshape(-1, 1)\n",
    "#print test_stock_X_p, test_gap_X_p, test_fai_X_p\n",
    "\n",
    "inv_yhat = concatenate((yhat, [[test_stock_X,test_gap_X, test_fai_X]]), axis=1)\n",
    "print inv_yhat\n",
    "#inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "\n",
    "test_stock_y = test_stock_y.reshape((len(test_stock_y), 1))\n",
    "inv_y = concatenate((test_stock_y, test_stock_X[:, 1:]), axis =1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.50825691]\n",
      " [ 0.51009172]\n",
      " [ 0.50091743]\n",
      " [ 0.48440367]\n",
      " [ 0.49541286]]\n"
     ]
    }
   ],
   "source": [
    "#inv_yhat = concatenate((yhat, test_stock_X[:, 1:]), axis=1)\n",
    "#print inv_yhat\n",
    "#inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "#inv_yhat = inv_yhat[:,0]\n",
    "#test_stock_X = test_stock_X.reshape((len(test_stock_X), 1))\n",
    "\n",
    "#inv_yhat = concatenate((yhat, test_stock_X[:, 1:]), axis=1)\n",
    "#print inv_yhat\n",
    "#inv_yhat = inv_yhat[:,0]\n",
    "test_stock_y = test_stock_y.reshape((len(test_stock_y), 1))\n",
    "print test_stock_y\n",
    "inv_y = concatenate((test_stock_y, test_stock_X[:, 1:]), axis =1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
