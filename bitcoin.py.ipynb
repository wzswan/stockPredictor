{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Market Cap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-11-22</td>\n",
       "      <td>8077.95</td>\n",
       "      <td>8302.26</td>\n",
       "      <td>8075.47</td>\n",
       "      <td>8253.55</td>\n",
       "      <td>3633530000</td>\n",
       "      <td>134851000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-11-21</td>\n",
       "      <td>8205.74</td>\n",
       "      <td>8348.66</td>\n",
       "      <td>7762.71</td>\n",
       "      <td>8071.26</td>\n",
       "      <td>4277610000</td>\n",
       "      <td>136967000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-11-20</td>\n",
       "      <td>8039.07</td>\n",
       "      <td>8336.86</td>\n",
       "      <td>7949.36</td>\n",
       "      <td>8200.64</td>\n",
       "      <td>3488450000</td>\n",
       "      <td>134167000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-11-19</td>\n",
       "      <td>7766.03</td>\n",
       "      <td>8101.91</td>\n",
       "      <td>7694.10</td>\n",
       "      <td>8036.49</td>\n",
       "      <td>3149320000</td>\n",
       "      <td>129595000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-11-18</td>\n",
       "      <td>7697.21</td>\n",
       "      <td>7884.99</td>\n",
       "      <td>7463.44</td>\n",
       "      <td>7790.15</td>\n",
       "      <td>3667190000</td>\n",
       "      <td>128425000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date     Open     High      Low    Close      Volume    Market Cap\n",
       "0 2017-11-22  8077.95  8302.26  8075.47  8253.55  3633530000  134851000000\n",
       "1 2017-11-21  8205.74  8348.66  7762.71  8071.26  4277610000  136967000000\n",
       "2 2017-11-20  8039.07  8336.86  7949.36  8200.64  3488450000  134167000000\n",
       "3 2017-11-19  7766.03  8101.91  7694.10  8036.49  3149320000  129595000000\n",
       "4 2017-11-18  7697.21  7884.99  7463.44  7790.15  3667190000  128425000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import numpy as np\n",
    "import bs4\n",
    "import html5lib\n",
    "\n",
    "bitcoin_market_info = pd.read_html(\"https://coinmarketcap.com/currencies/bitcoin/historical-data/?start=20130428&end=\"+time.strftime(\"%Y%m%d\"))[0]\n",
    "bitcoin_market_info = bitcoin_market_info.assign(Date=pd.to_datetime(bitcoin_market_info['Date']))\n",
    "\n",
    "bitcoin_market_info.loc[bitcoin_market_info['Volume']==\"-\",'Volume']= 0\n",
    "\n",
    "bitcoin_market_info['Volume']= bitcoin_market_info['Volume'].astype('int64')\n",
    "\n",
    "bitcoin_market_info.head()\n",
    "                                   \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Market Cap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-11-22</td>\n",
       "      <td>360.31</td>\n",
       "      <td>381.42</td>\n",
       "      <td>360.15</td>\n",
       "      <td>380.65</td>\n",
       "      <td>800819000</td>\n",
       "      <td>34544000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-11-21</td>\n",
       "      <td>367.44</td>\n",
       "      <td>372.47</td>\n",
       "      <td>350.69</td>\n",
       "      <td>360.40</td>\n",
       "      <td>949912000</td>\n",
       "      <td>35220200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-11-20</td>\n",
       "      <td>354.09</td>\n",
       "      <td>372.14</td>\n",
       "      <td>353.29</td>\n",
       "      <td>366.73</td>\n",
       "      <td>807027000</td>\n",
       "      <td>33933400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-11-19</td>\n",
       "      <td>347.40</td>\n",
       "      <td>371.29</td>\n",
       "      <td>344.74</td>\n",
       "      <td>354.39</td>\n",
       "      <td>1181530000</td>\n",
       "      <td>33284900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-11-18</td>\n",
       "      <td>331.98</td>\n",
       "      <td>349.62</td>\n",
       "      <td>327.69</td>\n",
       "      <td>347.61</td>\n",
       "      <td>649639000</td>\n",
       "      <td>31800700000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date    Open    High     Low   Close      Volume   Market Cap\n",
       "0 2017-11-22  360.31  381.42  360.15  380.65   800819000  34544000000\n",
       "1 2017-11-21  367.44  372.47  350.69  360.40   949912000  35220200000\n",
       "2 2017-11-20  354.09  372.14  353.29  366.73   807027000  33933400000\n",
       "3 2017-11-19  347.40  371.29  344.74  354.39  1181530000  33284900000\n",
       "4 2017-11-18  331.98  349.62  327.69  347.61   649639000  31800700000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eth_market_info = pd.read_html(\"https://coinmarketcap.com/currencies/ethereum/historical-data/?start=20130428&end=\"+time.strftime(\"%Y%m%d\"))[0]\n",
    "\n",
    "eth_market_info = eth_market_info.assign(Date=pd.to_datetime(eth_market_info['Date']))\n",
    "eth_market_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bitcoin_market_info.columns = [bitcoin_market_info.columns[0]]+['bt_'+i for i in bitcoin_market_info.columns[1:]]\n",
    "eth_market_info.columns = [eth_market_info.columns[0]] + ['eth_' + i for i in eth_market_info.columns[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEXCAYAAAD4LtBgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl8XFX5x/HPk31t0jTdtxTaAqXspewVRIGfgriBKJuA\n4oKK20/BDURR3MCf4gICsogiIkoFBApll4ItUHa6UrrRNt2TNMtMnt8f9yadpFmm7WTmTvJ9v17z\nyp1z79z7zE0yz5xzzz3H3B0REZGoycl0ACIiIl1RghIRkUhSghIRkUhSghIRkUhSghIRkUhSghIR\nkUhSghIRkUhSghIRkUhSghIRkUjKy3QAfa26utpramoyHYaISL83b968Wncfmqr99fsEVVNTw9y5\nczMdhohIv2dmy1K5PzXxiYhIJClBiYhIJClBiYhIJClBiYhIJClBiYgIdz+/ghUbGzIdRgdKUCIi\nA1xjS5yv3jmfj103J9OhdJC2BGVmXzGzV83sFTP7i5kVmdkEM3vWzBaZ2V/NrCDctjB8vihcX5Ow\nn0vD8jfN7MR0xS8i0l9taWwBYOWmbRmOpKO0JCgzGw18CZjm7lOBXOAM4CfANe4+EdgIXBC+5AJg\nY1h+TbgdZjYlfN2+wEnAb80sNx3vQUSkv9qyrSXTIXQpnU18eUCxmeUBJcBq4N3AXeH6W4APhsun\nhs8J1x9vZhaW3+HuTe6+FFgETE9T/CIi/VJdUxyAy0+ZkuFIOkpLgnL3lcDPgbcJEtNmYB6wyd1j\n4WYrgNHh8mhgefjaWLj9kMTyLl7TzswuNLO5ZjZ33bp1qX9DIiL9yLbmIEFNHlGe4Ug6SlcT32CC\n2s8EYBRQStBE1yfc/Xp3n+bu04YOTdmwUCIi/dLysPdecX60rpikq4nvPcBSd1/n7i3A3cBRQGXY\n5AcwBlgZLq8ExgKE6yuA9YnlXbxGRER2wTfuegmA4oKBmaDeBg43s5LwWtLxwGvAo8BHw23OBe4J\nl2eGzwnXz3Z3D8vPCHv5TQAmAc+l6T2IiPRrUatBpWU0c3d/1szuAp4HYsALwPXAfcAdZvbDsOzG\n8CU3AreZ2SJgA0HPPdz9VTO7kyC5xYCL3D2ejvcgItLfVZUWZDqEDtI23Ya7XwZc1ql4CV30wnP3\nRuC0bvZzJXBlygMUERngyovyMx1CB/1+PigREelZzZAS9h9TmekwdqChjkREBriWuJOfG710EL2I\nREQkrVrirRTkWabD2IGa+EREBqg/zVnGd/75CgB5OdGrr0QvIhER6XNNsXh7cgLUxCciItFQ1xjr\n8Dw/gk18SlAiIgNQQ3PHW0jz1cQnIiJRsEOCUhOfiIhEQX2zmvhERCSCVnWaPVdNfCIiEgm1W5s6\nPM/PVQ1KREQioDHW2uF5fl700kH0IhIRkT7X1NIpQamThIiIREFjLE5ezvZmPTXxiYhIJDS1tHaY\noFA1KBERiYTGWJxCJSgREYmaxpY4hQkdI7K6ic/MysxsjJmV9WVAIiLS95pirRTlJyao6NVXeozI\nzKaa2a/NbAmwGXgb2Gxmi83sWjPbLy1RiohISjW1xCnMy9ImPjO7A/gzsBo4C6gGCsKfZwMrgdvD\n7UREJIvsWIOKXhNfTxMW/snd7+2ifCPwn/DxYzM7uU8iExGRPtPYEqcoWztJdJOcdnk7ERGJjqZY\na6dOEtFLUDs95buZjQVOA9YAf3Z3T3lUIiLSp3asQUWvia/XlGlm/zKzk8LlQcCzwAnAt4Df9G14\nIiLSF7KhBpVMRNOBx8LlDwAvuftJwBHhcxERyTLZcA2q2yY+M/tjuFgB/NbMDJgBrDSzmwADysNl\n3P38vg5WRERSo3MNKi+bmvjc/Tx3Pw9YANwPfJugm/lFYTL6FLDJ3c9PJjmZWaWZ3WVmb5jZ62Z2\nhJlVmdksM1sY/hwcbmtm9iszW2RmL5nZwQn7OTfcfqGZnbub719EZMBxdxqaOtagCiJYg0omokuB\nm4DlwL3u/nJY/iFgzk4c6/+AB9x9b+AA4HXgEuARd58EPBI+B/gfYFL4uBD4HYCZVQGXAYcRND1e\n1pbUREQkOUtq62mOtzJ6cHF7WVY18bVx9/vCxFDq7psTVs0GHkrmIGZWQdA8+Mlwn81As5mdChwb\nbnYLwbWubwKnAreGPQTnhLWvkeG2s9x9Q7jfWcBJwF+SiUNEZKD7xUNv8vDrawEYVZHlCQrA3WME\nQx0llm3YieNMANYBfzSzA4B5wMXAcHdfHW7zDjA8XB5NUGNrsyIs6668AzO7kKDmxbhx43YiTBGR\n/u3Xsxe1LxdGfCSJnoY6utvMDu3pxWZ2qJndncRx8oCDgd+5+0FAPdub8wAIa0spuafK3a9392nu\nPm3o0KGp2KWISL9TmJfL9AlVAAT94KKlpxrUdQS99wYBjwNvAluBcmAyQXPbJuA7SRxnBbDC3Z8N\nn99FkKDWmNlId18dNuGtDdevBMYmvH5MWLaS7U2CbeWPJXF8EZEB75WVHRrCKMjL4Y+fPJS1W5sy\nFFHPeurF96C7HwqcSdCsdhjwUYLOCW8DZ7j7Ye4+q7eDuPs7wHIz2yssOh54DZgJtPXEOxe4J1ye\nCZwT9uY7HNgcNgU+CJxgZoPDzhEnhGUiItKDWLyVk3/9VIeywrwcSgvzmFBdmqGoepZMJ4m5wNwU\nHOuLBKOfFwBLgPMIEuSdZnYBsAw4Pdz2fuB9wCKgIdwWd99gZj8A/htud8VOXgsTERmQtjbGdijL\ny4les16ipMfiM7O9CcbgG+7uXwifF7j7S8m83t1fBKZ1ser4LrZ14KJu9nMTQbd3ERFJUl3Tjglq\n4rBozz+bVL9CMzsNeJKgx9w5YXEZcHUfxSUiIim0pbGlw/M9hpZGsmNEomQ7vl8BvMfdPwvEw7L5\nBDfciohIxHVu4kucTTeqkk1Qw4C2pjxP+KmpNkREskBdmKAGl+QDMKhop2dbSrtkI5xHMM37rQll\nZwDPpTwiERFJua1NQRPfXZ87krvmreDcI2oyG1ASkk1QXwIeCnvblZrZgwT3Qp3QZ5GJiEjKNLa0\nAlBakMc3T9o7w9EkJ9mhjt4Ie+2dDNzL9oFj6/oyOBERSY1Ya3BFJorTanQnqQRlZqOBBne/M6Fs\nsJmNcvdVfRadiIikRCwe1KCifu9TomQ7SfyTYFihRGOAf6Q2HBER6QvxsAaV2w8T1OSEeaAACJ9n\nR0OmiMgA197ElxO9aTW6k2yk68xsYmJB+Hx96kMSEZFUa2/iy6JrUMkmqJuAv5vZyWY2xcxOIRiR\n/Ia+C01ERFKlrQaVG/HRIxIl2838KqAF+DnBNBjLCZKThjoSEckCsbiTY5CTRdegku1m3gr8LHyI\niEiWibV6Vl1/gh4SlJnNcPcnwuV3d7edu8/ui8BERCR5LfFWvv+vV7nouImMrCjeYX28tTWrrj9B\nzzWo3wJTw+Ubu9nGgT1SGpGIiOy0x99cx5/mvE3t1mZ+f/YhO6xviXtWdTGHHhKUu09NeDrR3ePd\nbSsiIpnVGAs+orvrA7Fq0zYGFeWnMaLd12uDpJnlAnVmVpiGeEREZBc0x4Ju5AV5O36suzuPLVjH\nUROHpDus3dJrggprTguA7HpnIiIDSHuCyt3xY72uKUZzrDXyM+h2lmw389uBe83s/4AVJMwDpU4S\nIiKZ19gSNPHNen0N67Y2MbR8e6PXxvpgqo2q0uxqCEs2QX0u/Hl5p3J1khARiYBrH10EwKaGFq6e\ntYAff3i/9nUbGpoBqCrNrmtQyd4HNaGvAxERkV1XW9fcvvzmO1s6rNtYH6wbXFKQ1ph2V4/XoCxw\noZn9ysw+maaYRERkJ00ZOah9uTAvt8O6DfVtNah+lKAIhjb6PjAC+LGZfb/vQxIRkWS4O3957m02\nNTTz2urttabC/O0f7XOWrOdrf5sPwOB+lqBOB97l7qcDxwOf6PuQREQkGf94YSWX3v0yB14xq0N5\nYUJX85888Eb7cnlhst0OoqG3BFXh7gsA3P01oKrvQxIRkWR89c75XZYXJDTxJd63a1k0kjn03knC\nzGwC299jbqfnuPuSvgpORESSc8j4wcxbthGA/yyqbS/f2hjLVEi7rbcaVCmwKOExCFic8Hxhn0Yn\nIiJJKSvM408XHAbA+vpmNm9r4fXVW1i4tg6AW8+fnsnwdkmPCcrdc9w9N/zZ1SO3p9d3Zma5ZvaC\nmd0bPp9gZs+a2SIz+6uZFYTlheHzReH6moR9XBqWv2lmJ+78WxYR6R/evfew9uWywjyOnlTN5OHB\naBE3PrmEdVubAPjwQaOZMXloRmLcHemeHORi4PWE5z8BrnH3icBG4IKw/AJgY1h+TbgdZjYFOAPY\nFzgJ+G04VqCIyICzrXn7GN6VJcFNuNd+4mAAfjV7EVf9O+ggcc6RNWmPLRXSlqDMbAzwfsJp4i24\nWvdugqnjAW4BPhgunxo+J1x/fLj9qcAd7t7k7ksJmhmzr94qIpICDS3bE1TbvU+ThpW1j2je1vW8\nKD+7Jipsk84+h78EvgGUh8+HAJvcve0K3gpgdLg8mmBaedw9Zmabw+1HA3MS9pn4mnZmdiFwIcC4\nceNS+y5ERCKioSnG9AlV4PCpY4IBf8yMkvxc6hNqV0V52dnQlJa0amYnA2vdfV46jufu17v7NHef\nNnRo9rW7iogko6E5ztjBJdz52SMYVbl9Ft3igo4JqVA1qB4dBXzAzN4HFBH0Bvw/oNLM8sJa1Bhg\nZbj9SmAssMLM8oAKYH1CeZvE14iIDCjbWuKUFOxYO+o85cbw8qJ0hZRSSaVVM1tuZm938VhoZo+a\n2RfDRNIld7/U3ce4ew1BJ4fZ7n4m8Cjw0XCzc4F7wuWZ4XPC9bPd3cPyM8JefhOAScBzO/meRUT6\nhfqmWJcJqtU7Ps/Jsqne2yRbg/oVcFb4czkwDrgI+BuwAfgaQc3mGzt5/G8Cd5jZD4EXgBvD8huB\n28xsUbj/MwDc/VUzuxN4DYgBF2kqehEZiOKtTlOslZKCHT/GHe/iFdkn2QT1SeC97r6qrcDM/g08\n5O77mtmjwMMkkaDc/THgsXB5CV30wnP3RuC0bl5/JXBlknGLiPRLDc1B/7KualBN4ey62S7ZK2cj\ngbpOZfXAqHB5AVCZqqBERKRnbfdAlRTumKA2NbS0L591ePb2ZE42Qf0LuMfM3mNme5vZe4C/h+UA\nRwBv9UF8IiLShbZu5F3VoNqcvP9IvvP+KekKKeWSTVCfAZ4FriO4VnQ98F/gs+H6JQQ34YqISBps\nb+Lr/krNtZ84mKL87LwHCpKf8r0RuCR8dLX+nVQGJSIiPVtaWw/0XIPKdknfB2VmewEHAGWJ5e5+\nU6qDEhGRnn3hzy8APdegsl1S78zMvgV8D5gPNCSsckAJSkQkQ4aVF2Y6hD6TbOr9MjDd3V/qy2BE\nRKR38fBO3KrSAsZWlWQ4mr6TbCeJbcAbvW4lIiJ9bub8gTHCW7IJ6rvAr81spJnlJD76MjgREdlR\ncX7Q+PWld0/McCR9K9kmvpvDn59KKDOCa1D9twuJiEgkBU180ycM6XLtredPZ2NDczoD6hPJJqgJ\nfRqFiIgkrW0oo+6m0cjG6d27kux9UMv6OhAREQF3x6zn0cfbElTnaTX6m24TlJld7+4Xhsu3QdfD\n47r7OX0Um4jIgHL+zf8F4KZPHtrjdr3VoPqLnmpQSxOWF/V1ICIiA9nCNVuZ/cbaXreLxVu5dvZC\nAApz+3cXgJ4mGfxxwvL30xOOiMjA9N5rnuhx/SsrN3Pyr59i/zEVrNnSBEB5Uf8dRQKSn1H3uHAG\nW8xshJndYmZ/NLMRfRueiMjA4+6s2dLYoexfLwXT8b20YnN7WbbOlJusZBswfwu0zVx7NZAPtBKM\nai4iIik04dL7OexHj7C+rqm9rCivfzfndSXZ+uFod3/bzPKAE4HxQDOwqueXiYhIMqrLCqit63jv\n0urNjQwpC8bay+tUW/rpR/ZPW2yZkmyC2mJmw4GpwGvuXmdmBQQ1KRER2U3FBbmMrChi9ebtTXsP\nv76Gi+94gY8cMqbDmHufOGwcpx86NhNhplWyTXy/Jpig8HbgN2HZUWh8PhGR3balsYXlG7bR+YrS\nLx9eyOJ19fz0gTdpisXby927vOun30n2Rt2fmNk/gLi7Lw6LV9Jx6CMREdkFTy6oBWDTtpZut1my\nLpigcNKwMi44emAM7rMzd3ktAUab2cfNbAawxN1f7qO4RET6vW3NcWouuY/fPR7cavrgl2dQXpjH\neUfV8IEDRnXYdnGYoG7/9GFMHFae9lgzIdkJC/cG/gUUA8uBsUCjmZ3i7q/3YXwiIv3WO2FX8ldW\nbqEgN4cxg4uZf9kJ7d3Hp0+ooqE5xo/uf4OHX18DQH5O/x49ItHOdDO/Hhjr7ke4+xjg92G5iIjs\ngs0JTXrDBhViZh3ubTrr8PGcMX1ch9fk5vbve58SJZugDgSu9o5X5n4ZlouIyC7YWL+9W3l+NwO/\nDirKp2bI9h58qkHtaBXwrk5lx6D7oEREdtmGhAS1tLa+2+0+esiY9uXigoFzw26yCepbwEwzu8PM\nfmJmdwAzw/JemdlYM3vUzF4zs1fN7OKwvMrMZpnZwvDn4LDczOxXZrbIzF4ys4MT9nVuuP1CMzt3\n596uiEh0JCaoPYeWdrtdeVFwy+nxew/r85iiJKkE5e4zgYOBV4Dy8Och7n5PkseJAV9z9ynA4cBF\nZjYFuAR4xN0nAY+EzwH+B5gUPi4EfgdBQgMuAw4DpgOXtSU1EZFss3Dt1vblnqbYKCsM+rM1x1v7\nPKYoSXooXHdfAPxwVw7i7quB1eHyVjN7HRgNnAocG252C/AY8M2w/NbwmtccM6s0s5HhtrPcfQOA\nmc0CTgL+sitxiYhk0p1zV7QvDx9U1O12baOWx+ID4wbdNj1NWNjtJIWJdnbCQjOrAQ4CngWGh8kL\n4B1geLg8mqA7e5sVYVl35SIiWSWxz9kfzzuUovzury21NfGpBrVdyicpNLMy4O/Al919S+K0xu7u\nZpaSrwdmdiFB0yDjxo3rZWsRkfRru/502SlTOG6vnq8tjawIalcDZYijNj1NWJjSSQrNLJ8gOd3u\n7neHxWvMbKS7rw6b8Nqmk1xJcDNwmzFh2Uq2Nwm2lT/WRezXE04FMm3atIH1GxWRyKtvivHEwnUA\njBlc0svWMH5ICZf+z96cuO/AmoKvx04SZnakmf2km3VXmdnhyRzEgqrSjcDr7n51wqqZQFtPvHOB\nexLKzwl78x0ObA6bAh8ETjCzwWHniBPCMhGRrHHuTc/xlb/OB2DM4OJetzczPvOuPamp7r6nX3/U\nWyeJb9P9aBGPh+tPSeI4RwFnAy+b2Yth2beAq4A7zewCYBlwerjufuB9BM2MDcB5AO6+wcx+QDCy\nOsAVbR0mRESyxdxlG9uXRyeRoAaq3hLUgcAD3aybRVAr6pW7PwU7jCTf5vgutnfgom72dRNwUzLH\nFRGJmk0NHSclHFSkafW601uCGgQUANu6WJdPcE+UiIgkac2WYBr3Dx88mouOm5jhaKKttxt13yC4\nztOVE9CEhSIiO2XVpuD7/mmHjGXPoWUZjibaeqtBXQNcZ2a5wD/dvdXMcoAPEsys+9W+DlBEpD+5\n8amlDCktYL8xFZkOJfJ6TFDu/mczG0EwykOhmdUC1UATcJm7awQHEZEk1TfFeGbJej77rj3ahy+S\n7vV6htz9ajO7ATgCGAKsB55x9y19HZyISH8yZ8l64q3OEXtUZzqUrJBUCg+Tke43EhHZDfNXbMYM\nptVojOtkDJyZr0RE+kBTLM7arY29DkO0ZksjNzy5hD2qS3scd0+2UyOoiMhu+PyfnueRN9Zy5mHj\n2NYS5wenTqW00/WluqYYx/38MRqa41xx6tQMRZp9lKBERHbR7DfW8MgbwRCitz/7NgAfPmgMR0+q\nxt353eOLue2ZZaze3AjA6Mpijpqo60/JUhNflntiwTpqLrmPy2e+mulQRPqNK+97jZpL7utxm7fX\nN3D+zXN3KL9tzlvE4q185a8v8tMH3uyQnG67YHqfxNtfqQaV5c656TkAbv7PW1z+gX0zHI1I//CH\nJ5cC0BJvJT93+/d4d+fxBeuYMnIQv5j1JgDnHDGekRXF/OSBYNyCB19dw08ffJN/vrgKgPu+dDRD\nSgsZUdH9hITSNSWoLNYywCYvE0m3jfXNDBu0fS6mj103h+fe2j4+9fSaqvZrSmccOpaDfjALgOuf\nWALA7Z86jH1H6YbcXaUmviy2bH1Dh+dH/2R2h+ebt7WweF1dOkMSyXoX3Pzf9uX19dsHdn1qUW2H\n5FRRnM/VHzug/fng0oIO+ykpyOWIPYb0YaT9n2pQWWzZ+voOz1ds3MamhmYqS4J/lON+/hgb6pv5\nzIw9uPR9+7C1sYXcHKOkQL92ka58/W/z2zs9AHzuT/MozMvlzTVbASjOz2XmF47irnkruODoCe21\nqza/P+sQPvuneQA8/r/HkZPT3SQOkgzVoLLYW2EN6szDtk9rf8I1TwBBc0TblNLXPbGEmkvuY7/L\nH+LYnz3GfxbVEm/VRMMiiRpb4tw1bwUA91x0FBD8j7Ulp6rSAi75n72ZNLycS9+3zw7JCeCkqSN4\n7tvH88CXj2FoeWH6gu+n9FU6i/00vCg7cdj2EZFzw29sbf9Una3d2sQnbniWb5y0F58/VkP9S2Y1\nx4LrqAV5mfmuvHLTNtbXNbG+rpnHFwRTsF9/9iEcMLaS3555MJ+//XkAbj7vUI7cszqpOIeVFzGs\nXB0iUkEJKkut3ryNpvCfOxbfXhvKMeOKf73GTU8HvZD2qC7lhx+cyssrN/Pjf2+fHWXmi6uUoCTj\nTv71kyxYU8d9Xzq6TzsTPL2olqcW1XLMxGqeWFjL7x9fzNTRg1iyrp6G5nj7dtPGD2bG5KEA7b3u\njplUzbF7Deuz2KR71tvwHNlu2rRpPnfujvcqZLu2ezR+/fGDWLu1iR/c+9oO2/zviXt1mBCtrinG\n1sYWrnt8CTf/5y2uO/sQTpgyHDPj5RWbaXXngLGVuxzT+romXl+9lYPGVXa4k97dMVNbvHQ0Z8l6\nzrh+DgDvmjyUZevreWt9A7847QCW1tYzcVgZ+4+pYFRl8S4PDRSLt3LdE0v42YNv7rAux4Ka27sm\nD+WDB45m0vDyDq0RAG/V1lNTXbpLxx6IzGyeu09L1f5Ug8py+4+pYPigIjbWNzO0vJDLwht2u5qt\ns6wwj7LCPI7bexg3/+ctPnNbcDH3/i8dwynXPgUE/7AfOGAUV5y67051pmiKxTnyqtnttboff3g/\n9htdwdsbGvjanfPJyzH2HlnO8EFFHDxuMKdNG0NZYZ4S1wDWNvIC0N68BvC1v83vsF3NkBLu+9Ix\nOwwfVN8U46//Xc7WxhgHjquktCCXbS1xNtQ38/SiWuYt28jbGxpoCVsYCvJyOGrPIRwyfjBnH1FD\nRXHvU60rOWWWalBZqq0G9cr3T2yfV+aeF1dy8R0vAvD8d99LVadur4kuvftl/vLc292uB/jU0RP4\nzslTeo1lc0MLB1zxULKhd1BRnM8h4wfz2zMP1gCaA8S25jjfvecV7pq3ghmTh/Li2xvZ0hgD4OT9\nR/L0olo+f+xESgpzeW3VlvZEVlGcz/ghJZgZlcX5PLN4Pc093AtYmJfD1NEVjBhUxFUf2Y/yot4T\nkuwe1aCkw6jJiZOetdVGJg8v6zE5AVxx6r68d8qwDkO1/P1zR3DI+CpufGopP7j3NW54ainfOGlv\nCvJy+OXDC7j3pdV8/YTJvGef4eQl3F3/9bvmtx/3gYtn8OW/vsjM+auYXlPF2xsauOZjB3L4HlXE\nW5283BxeWrGJH9//BnF3DJj9xlr2/u4DVJcV8rFDx/Chg0YzurKE4gIlrP7m5RWbOf26Z9jWEscM\nzjpsHFd+cCqbt7UwdXTX16DaEtQRewzhjXe2MKKiiA31zUweUcb5R01g8vBy6ppiLN/QQGVJAWOr\niqkqLWBoWaFq6FlONagsVFvXxLQfPsy337cPn56xR3t5Q3OML/3lRS47ZQpjq0qS2teG+mbufn4F\nR+w5pMNF6m/e9RJ/nbscCD4Ynlmyvn3d0PJCPjNjDxqa49Q1xbj+iSUMH1TIM5ccv9P3fbS2Ont8\n6/4u15UU5PKZGXtyzhHjd7gJsjNd50rO1sYWvnrnfNZubWKP6lKOnljNHkNLuf/l1ew/ppL37zey\ny9/hmi2NNDTHqW+KsfeI8g5fUFpbvf01ra3O8o0N/Gv+Ku5+fiUnTh1BQ1OMooJc6ptiLFvfwNOL\navnF6QfwoYPGJBXz8g0NVJTkM0g1oMhLdQ1KCSoLffWvL3L3Cyv5x+eP5KBxfTPx2ZotjRz2o0c6\nlNUMKWm/9ypRYV4Oj/3vsYysKN6lY63evI0v/vkFvvLeycRanXvnryIvN4fFa+va79z/4IGjuOyU\nfdnS2MKtzyxj31GDOGHfEe01yA/99mkWvLOVe75wNKWFudRubWZ4ReGA7O77ysrN/Oj+17n4+Ekc\nFo5kEG91Vm3axqm/ebr9/riefPOkvdlnZDk5Ztw2ZxmzXlvTYf3wQYW0OpQW5LJqcyOFuTlsa4nT\n6k5vt9h96KDRXPOxA3f5/Ul0KUHtpP6WoJ5YsI5zbnquvTmtL+9Ud3cWrq1rv/n3xe+9F3dYtK6O\nhuY4uWYMLs1nTGUJFSWp/3a7ctM2jrqq4/BNZYV51DXF2p9XlxWw3+gKHn1zXeeXA3BozWAOGV9F\nWWEux+41jLFVJUldHM9W8VbnyKseYc2WJgBOnzaGI/es5oanlvDKyi0AjK0q5p+fP4onF9byxIJ1\n7D+mgtGDS/j0rd3/nxwwtpIpIwcxsqKIf76wklGVxZgF990NKy8kx4yq0gJyzBhSVsC7Jg9l2KAi\nWmKtVJbk4w5LaoNht/YcWqbabj+lBLWT+luCausccev509vv1+hrjy9YR1FeTvu38XRyd2KtzqV3\nv8xd81aw1/ByvvDuiSxeV8cvH17Yvt30CVWMqiji1VVbOHHfEYwZXMzTi9fz1MJ1bGxo6bDP0ZXF\n/PCDUzkIv+HbAAAT5UlEQVRu72Gs3dJIc7yVMYNLdjjuA6+8w5wl61lf38zoymJOPXA0U0YNal+/\nqx+y7k5teGPotbMX8t4pw8nPzWH5xm2MHRxcPzlswhD2GFq6Q8+17qzevI1nl2zg/pdX81Cn2k6b\nfUYO4rPv2oNTDxzd5fpnFq/n8QXr+MjBo1m+sYGXV2xhaHkhh9YMZtLw8l16rzKwKEHtpP6QoDbW\nN+PAa6u2cNaNz/KxaWP5yUf3z3RYaeXuPLt0A/uPqWjv/u7uvLW+gaL8nG6bFxtb4tz41FLW1zWz\nob6pfQoEgK+fMJlfz15EU6yVoyYOYfLwcm7+z1tUlxVSXpTHknX1Xe4zx2BQcT4n7TuCkRXFrN3a\nSFOslRUbG2iOtVJckEt+bg75uTlUlxUwrqqUzdtaeHpRLc2xVhpaYizfsG2H/VaW5LOpUzKdUF3K\nCfsOJxZ33tnSSFFeLqWFuRTn57JuaxPr65tZu7WJhWu2Emt18nKMfUcN4pbzp/PUolo2NbQwfFAR\nIwYVsd8YjaotfUsJaidle4JavqGBD/7m6fZRlYeVF/LQV2a0DwgrO2fxujoWr63jwvAesK7k5xp7\nDi3jiD2HcNbh45kwpJR75q/k6UXreeOdLUwaVk5tXRPPLF5PrNUpzMuhKdbKkNIChg8qoqQgl5ZW\npyXWytsbGqhripGXY4ysLKJmSCmFeTlMGl7OHtWlvGef4cRaHXdn2KAimmJxnl5Uy+urt/KbRxe1\nj3KQl2OMrSqhoTlGfVOc5lgrQ8sLqSotYEhZASMrijhiz2pmTKrW34ZkjBIUYGYnAf8H5AI3uPtV\n3W27OwnqB/e+xo1PLWXa+MEcPamazdta2LythbrGGE2xVsZVlTBpeBmjKorZ0thCZUk+B4ypZEhZ\nIYvX1WFAfm4Oa7c2saG+mXhrK9ta4ixeW8+GhmYWr61j3dYmyovyaIk7FcX5OM7yDdtobIkzsrKo\n/bqBWTAyxMn7jWLckOR66EnXWlud0657hrwc44Zzp+FAXWOMeKtTVVqQdLNaXVOMppY4VaUFuNPl\n9cCmWJx4q1Ocn7tLTYKL19UxpLSAiuL8Dq9Xr0WJogF/H5SZ5QK/Ad4LrAD+a2Yz3X3HsX52U9td\n5HOXbWTuso2UFeZRUZxPeVEwAsJ/39rQYRyvNtVlBdTWdd9TKi/HqCzJp6wwj6rSAtbVNTFyUDEt\n8VacIBmVF+UxuKSAzx+7J2ccOk5JKYVycoy/f+7IDmW70oW5bWQOCH5nXSnM2717ufYcWtZluZKT\nDARZl6CA6cAid18CYGZ3AKcCKU9QZx8+ng8dNJrlGxqYNKysw70fEAy1smhtHU1hc8tbtfX844WV\nrNjYwHlHTQh7NQX3DbV1dy4pyGX4oKKkv6WLiAxU2fgpORpYnvB8BXBY4gZmdiFwIcC4cePYHWWF\neewzclCX60oL8zoMrjqhupTj9taoxyIiqdAvJyx09+vdfZq7Txs6ND1dsUVEJLWyMUGtBMYmPB8T\nlomISD+SjQnqv8AkM5tgZgXAGcDMDMckIiIplnXXoNw9ZmZfAB4k6GZ+k7u/muGwREQkxbIuQQG4\n+/1A10Ngi4hIv5CVN+ruDDNbByxL4yGrgdo0Hq8nUYklKnFAdGKJShygWLoSlTggu2IZ7+4p65nW\n7xNUupnZ3FTeSb07ohJLVOKA6MQSlThAsUQ5DhjYsWRjJwkRERkAlKBERCSSlKBS7/pMB5AgKrFE\nJQ6ITixRiQMUS1eiEgcM4Fh0DUpERCJJNSgREYkkJSgREYkkJSgREYkkJSgREYkkJSgREYkkJSgR\nEYkkJSgREYkkJSgREYkkJSgREYkkJSgREYkkJSgREYkkJSgREYkkJSgREYmkvHQezMzygcOBA4BK\nYBMwH5jj7i3pjEVERKItLdNtmNkQ4FLgXGAD8AawFSgH9gEGA7cAV7l7T/Pdi4jIAJGuGtRTwI3A\nge6+svNKMxsFnAk8AUxJU0wiIhJh6apBFbh7c6q2ExGR/k8z6oqISCSltZMEgJlNAK4EDgTKEte5\n+7h0xyMiItGU9gQF/BlYDHwNaMjA8UVEJAukvYnPzLYAle7emtYDi4hIVsnEjbpPAAdl4LgiIpJF\nMtHE9xbwgJn9A3gncYW7fy8D8YiISARlIkGVAvcC+cDYhHJ1JxQRkXbqZi4iIpGUiRoUZjYJOB0Y\nBawC7nT3hZmIRUREointnSTM7BPAC8D+QD2wH/B8WC4iIgJkppv5EuCT7v5EQtkxwG3uXpPq41VX\nV3tNTcp3KyIincybN6/W3Yeman+ZaOIrB57pVDaHoPNEytXU1DB37ty+2LWIiCQws2Wp3F8m7oO6\nGviRmRUBmFkxwdBHV2cgFhERiai01KDMbDnbu5EbMAK42Mw2EswFZcBq4MfpiEdERKIvXU18Z6Xp\nOCIi0k+kJUG5++PpOI6IiPQfmbgGJSIi0islKBERiSQlKBERiSQlKBERiaS0JigzG29mQxOen2Jm\nM83sD2Y2Ip2xiIhItKW7BvU3YAIEyQr4E/AfoAC4Oc2xiIhIhKXrRt0ZBDfjTgbKw+enAM8TJKjn\ngDvDchLH6RMRkYEpXTfqTgh/GlADxIDjgGfD5wbEE5aVoEREBrh03ah7C4CZnQNMBf5LkLQ+4O6r\nzKwM+I6735qOeEREJPrSfQ3qc8A+wNeBL7v7qrD8w8CdaY5FREQiLK3Tbbj7AuCkLspVcxIRkQ7S\nUoMys8JUbiciIv1fupr4XjSzb5jZqK5WmtlIM/sGwVTwIiIiaWviOwa4BJgfzgH1JrCVYHbdyUAl\nwX1QM9IUj4iIRFy6evHVAl83s28BhwH7ESSljcBVwHPu3pKOWEREJDuku5NEM/Bk+BAREemWBosV\nEZFIUoISEZFIUoISEZFIUoISEZFISnuCMrNCM7vSzJaY2eaw7AQz+0K6YxERkejKRA3qGoIBY88E\nPCx7lWCcPhERESDN3cxDHwImunu9mbUCuPtKMxudgVhERCSiMlGDaqZTYgyngV+fgVhERAa8mkvu\ny3QIXcpEgvobcIuZtU39PhK4FrgjA7GIiEhEZSJBfQtYCrxMMNzRQmAVcEUGYhERkYhKe4Jy92Z3\n/4q7lwHDgfLweVO6YxER6Q+i2kS3uzJyH5SZlZjZ/sAk4AgzO9LMjsxELCIiEs0kl/ZefGZ2DsE1\np2ZgW8IqB8alOx4REYmmTHQz/ynwEXeflYFji4hIlshUN/PHMnBcERHJIplIUN8Frjaz6gwcW0Sk\n34ridaTdkYkEtQD4ALDGzOLho9XM4hmIRUQkq/W3pJQoEwnqNuBW4ABgcviYFP4UEZE0iXpyy0Qn\niSHA99zde91SRES6FfUEs7syUYP6I3B2Bo4rIiJZJBMJajpwg5m9aWZPJD4yEIuISOTsTs2o5pL7\n2h/d7TNbal6ZaOL7Q/gQERnwai65j7euen9a9p9tSSrtCcrdb9ndfZjZxcCnAQP+4O6/3O3AREQk\nUjIx1NH53a1z95uSeP1U4BJgI9AKXGJmD7n7a6mLUkQkfRJrM13VpjrXsvq61hUVmbgGdXanx/8C\nvyf5jhMfAoYBo4CJ4fI/Ux+miEjf6qmZradrSANFJpr4jutcFtaq9klyF08QJNZtQAFBM9+KlAUo\nIpIFBkLCykQnia7cDNQS1KZ6szn8OSL86cBLiRuY2W3AhwGqqqpSE6GISJp1lYR2JjFlexJLexOf\nmeV0epQBFwKbktzFz8KfMWArQQ3qkD4IVURkp2R7QoiaTNSgYgS1nkQrCXrlJWMx8B4gFygPy2o6\nbfMkYZNhWVmZkpeIREJbAnvrqvcrmSUhEwlqQqfn9e5euxOvfyf8aQllnWuCxxAmqLq6up2LTkSE\nne8p15ZwlIRSJxOdJJbt5i46JziAyt3c54CWLV1WMxlnXx27q/2m4liJH5KJzxN17rbcVpbMB2zn\ndZ1f1/mYbeuT3Wdv+++tW3bb8Xd3n13FnOw5kt1n6Riz1cyeZMdmvR24+4wk9nUmcAFwHMG9UJXA\nG+4+JWGbCwmuawHsBby5C2HvqmqCDh9REJVYohIHRCeWqMQBiqUrUYkDohNLMnGMd/ehqTpgumpQ\nN6RwX6OBo4E4sAUoBZYkbuDu1wPXp/CYSTOzue4+LRPH7iwqsUQlDohOLFGJAxRLlOOA6MSSiTjS\nkqBSMbxRgjIgn6BGNhxoIhrfLkREJIUyMZIEZnaemc0ORzSfbWbn7cTLJxPUnuLAeoL7on7W4ytE\nRCTrZGIsvm8D5wC/AJYB44FvmNkod7+yt9e7+xlm9j7glwRdzW9y91f7MuadlJGmxW5EJZaoxAHR\niSUqcYBi6UpU4oDoxJL2ONLSSaLDAc2WAscm9uYzs/HAE+4+Pq3BiIhIZGWiia8UWNepbD1QnIFY\nREQkojKRoB4Abjezvcys2Mz2Bm4BHsxALCIiElGZSFBfIBhD7yWgDngRqAe+mIFY2plZj0NOmNlj\nZrZDF0szuz3s7PGKmd1kZvlhuZnZr8xskZm9ZGYHJ7zmATPbZGb3dtpXi5nND7e/KxyncGffx1fN\n7LVwH4+Ezadt6841s4Xh49yE8ivNbHnnc9D23Mw+Ymbe+f2n6Zy0xfCr3n5HaTonjWa2zsxeDB+f\nysA5aTGzpQkxHJjhc1JnZqeH+3vVzP6cgXNSF8a3wMxeN7MvZficNCf8fhaY2aZO69NxTuIJMawy\ns52elijF52ScmT1qZi+E+3tfrwG4e1oeQE7n5wRzOeWkK4Ze4qvrZf1jwLQuyt9HMOySAX8BPpdQ\n/u+w/HDg2YTXHA+cAtzbXQzA1cAlu/A+jgNKwuXPAX8Nl6sI7herAgaHy4PDdYcDIzufA4IvEOUE\nU5zM6fz+03VOgGnAbb39jtJ0ThqBazP8d9ICfHQ3/95TeU7qgRcSthuWgXPSCNxK+HnSOYZM/O8k\nLH+RoDNXJj9P/g6ck+Fzcn3C+5kCvNXb8dNZg1ppZj81s/0A3L3V3de6e2saY+iRmR2b+C3EzK41\ns0/29Bp3v99DwHPAmHDVqcCt4ao5QKWZjQxf8whBLbKrGMrM7BGCCRwvNrNTw/Ka8JvhH8JvqQ+Z\n2Q7X7dz9UXdvCJ/OSYjnRGCWu29w943ALOCk8DVz3H11N2/xj0ARwQdARs4JQbKuAYrN7OUInJPR\nmf47AYrCb7TPR+Cc5AMPE3yJwN3XZuCc5AM/B2aZ2fPAI5n+O0n4PPk48JcMfp48Fr7+mxk+Jw4M\nCpcrgFU9nQtIbxPfZwnG0Xsu/Ke62MxSNiRGpoVV8bMJrrFBMOLF8oRNVoRlvbkW2A94BZgO/MLM\n2gbGnQT8xt33JZie5CO97OsCgm9duxpPDjAUWJtE3DtI0TnJB+4B3k8wSeVxZPacAMwAZljQDDs2\nie3bpfDv5LsEN6o/TvBhkem/kzHAkWY2x8xOSiL+dik6JzkEH8KDgTUE7ynTfycQdP6aAMxOcnsg\npX8njcCfCWYdfxeZPSeXA2eZ2QrgfpK4rJO2BOXu97j7aQRVv+uA04AVZjbTgmsc+emKpY/8lqCr\n/JO7uZ9PA38jSFJPE/zSh4frlrr7i+HyPHacZqSdmZ1F0DS2Szcxm1kOUAj8bldeH9qtc2Jmowju\n1fsN8COCf/aHydA5CcWAMwiaPWcRdPDZGan4O2kGpoYxnEvwvjN5TiBIUM8Q1Bb+QDDbdbJS9b/T\nCPyHYCaD2WT+nACMAu5y9/hOvi5V58SAbxO8n0z/73wcuNndxxA0Wd4Wfs50K+2dJNx9k7tf5+5H\nE/whzQWuAbprTkmnGB3PSVEyLzKzywhqGl9NKF4JJH67HhOW9eZMgkEZTyPoSLImIY6mhO3idHOj\ntZm9h+CP8gPu3vaanY2nnOBcXAO8m6BdeSbbq/g9StE5OYjgH2wFcF64XEbmzkmbbQTn5gaCyTLT\n/XfiBH8nQwj+TuaR2XPiBHOwmbsvBRYQXF/uVYrPiYf7mkTwvjP9dxIjSFB/CZ9n4vPkMwSzj091\n9wPJ7Dm5ALgTwN2fCeOo7ukFGRnqCMDMCggy8mEEGf3lTMWSYBkwxcwKzayS4OJjjyzoxXUi8HHv\neD1tJnCOBQ4HNvdwTYOw2m0EbbNrCZq06glG2kiamR1EUEP9gLsnNs09CJxgZoPNbDBwAj107Xf3\nzeHxp4fxPAt8AjggiRhSck7c/T6gAfgBcFO4/GkydE7adkf4dwJ8mODDOG1/JwkxtP2dnEIwaHIm\nz0mMIClMCWu9exF8uegthlSekxhwMME5OYrgC28mzwkEH/ilwLx0f54kOAZY4u51ZnYcmT0nbxOe\nAzPbhyBBdb4ntiPfjZ5Au/IgGIn8eoKpMhYQtKWPT3ccnWLKA9aHyz8FFgIPAXcDn/See93ECGb5\nfTF8fC8sN4KmqcUEyXdawmueDH8x2whqBycSXGtpAV4j+CDeBPwJeJ2g6l0DvJKwj68Dl3cRz8ME\n35La4pmZsO58YFH4OC+h/KdhHK3hz8u7OCcNBBdJ03lO8ghu4q4maD6KE3TayOQ52Qa8SvBB2AA8\nlYFzkvh3spGgc0JG/04IOrLUEnwrfykD52QDwf9sffj4ZwTOyeUE/zOZ+Dxpi+Hp8Dy8TAb/d8Ly\nKWE888N9ndDrZ3Mak8Dl4RvZSJCgjkrXsZOI7QDguYEeQ9TiiUIMUYsnCjFELZ4oxBC1eKIQQ0re\nRxpP2L8JLi4XZfpNd4rrswTfRnvN5v05hqjFE4UYohZPFGKIWjxRiCFq8UQhhlQ90j5YrIiISDIy\n1klCRESkJ0pQIiISSUpQIiISSUpQIiISSUpQIiISSf8PUxwWz7CXMj4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7d625243d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2,1, gridspec_kw = {'height_ratios':[3, 1]})\n",
    "ax1.set_ylabel('Closing Price($)', fontsize=12)\n",
    "ax2.set_ylabel('Volume ($ bn)', fontsize=12)\n",
    "ax2.set_yticks([int('%d00000000'%i) for i in range(10)])\n",
    "ax2.set_yticklabels(range(10))\n",
    "ax1.set_xticks([datetime.date(i,j,1) for i in range(2013, 2019) for j in [1,7]])\n",
    "ax1.set_xticklabels('')\n",
    "ax2.set_xticks([datetime.date(i,j,1) for i in range(2013,2019) for j in [1,7]])\n",
    "ax2.set_xticklabels([datetime.date(i,j,1).strftime('%b %Y') for i in range(2013, 2019) for j in[1,7]])\n",
    "ax1.plot(bitcoin_market_info['Date'].astype(datetime.datetime),bitcoin_market_info['bt_Open'])\n",
    "ax2.bar(bitcoin_market_info['Date'].astype(datetime.datetime).values, bitcoin_market_info['bt_Volume'].values)\n",
    "fig.tight_layout()\n",
    "#fig.figimage(bitcoin_im, 100, 120 ,zorder=3, alpha= .5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>bt_Open</th>\n",
       "      <th>bt_High</th>\n",
       "      <th>bt_Low</th>\n",
       "      <th>bt_Close</th>\n",
       "      <th>bt_Volume</th>\n",
       "      <th>bt_Market Cap</th>\n",
       "      <th>eth_Open</th>\n",
       "      <th>eth_High</th>\n",
       "      <th>eth_Low</th>\n",
       "      <th>eth_Close</th>\n",
       "      <th>eth_Volume</th>\n",
       "      <th>eth_Market Cap</th>\n",
       "      <th>bt_day_diff</th>\n",
       "      <th>eth_day_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-11-22</td>\n",
       "      <td>8077.95</td>\n",
       "      <td>8302.26</td>\n",
       "      <td>8075.47</td>\n",
       "      <td>8253.55</td>\n",
       "      <td>3633530000</td>\n",
       "      <td>134851000000</td>\n",
       "      <td>360.31</td>\n",
       "      <td>381.42</td>\n",
       "      <td>360.15</td>\n",
       "      <td>380.65</td>\n",
       "      <td>800819000</td>\n",
       "      <td>34544000000</td>\n",
       "      <td>0.021738</td>\n",
       "      <td>0.056451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-11-21</td>\n",
       "      <td>8205.74</td>\n",
       "      <td>8348.66</td>\n",
       "      <td>7762.71</td>\n",
       "      <td>8071.26</td>\n",
       "      <td>4277610000</td>\n",
       "      <td>136967000000</td>\n",
       "      <td>367.44</td>\n",
       "      <td>372.47</td>\n",
       "      <td>350.69</td>\n",
       "      <td>360.40</td>\n",
       "      <td>949912000</td>\n",
       "      <td>35220200000</td>\n",
       "      <td>-0.016389</td>\n",
       "      <td>-0.019160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-11-20</td>\n",
       "      <td>8039.07</td>\n",
       "      <td>8336.86</td>\n",
       "      <td>7949.36</td>\n",
       "      <td>8200.64</td>\n",
       "      <td>3488450000</td>\n",
       "      <td>134167000000</td>\n",
       "      <td>354.09</td>\n",
       "      <td>372.14</td>\n",
       "      <td>353.29</td>\n",
       "      <td>366.73</td>\n",
       "      <td>807027000</td>\n",
       "      <td>33933400000</td>\n",
       "      <td>0.020098</td>\n",
       "      <td>0.035697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-11-19</td>\n",
       "      <td>7766.03</td>\n",
       "      <td>8101.91</td>\n",
       "      <td>7694.10</td>\n",
       "      <td>8036.49</td>\n",
       "      <td>3149320000</td>\n",
       "      <td>129595000000</td>\n",
       "      <td>347.40</td>\n",
       "      <td>371.29</td>\n",
       "      <td>344.74</td>\n",
       "      <td>354.39</td>\n",
       "      <td>1181530000</td>\n",
       "      <td>33284900000</td>\n",
       "      <td>0.034826</td>\n",
       "      <td>0.020121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-11-18</td>\n",
       "      <td>7697.21</td>\n",
       "      <td>7884.99</td>\n",
       "      <td>7463.44</td>\n",
       "      <td>7790.15</td>\n",
       "      <td>3667190000</td>\n",
       "      <td>128425000000</td>\n",
       "      <td>331.98</td>\n",
       "      <td>349.62</td>\n",
       "      <td>327.69</td>\n",
       "      <td>347.61</td>\n",
       "      <td>649639000</td>\n",
       "      <td>31800700000</td>\n",
       "      <td>0.012075</td>\n",
       "      <td>0.047081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  bt_Open  bt_High   bt_Low  bt_Close   bt_Volume  bt_Market Cap  \\\n",
       "0 2017-11-22  8077.95  8302.26  8075.47   8253.55  3633530000   134851000000   \n",
       "1 2017-11-21  8205.74  8348.66  7762.71   8071.26  4277610000   136967000000   \n",
       "2 2017-11-20  8039.07  8336.86  7949.36   8200.64  3488450000   134167000000   \n",
       "3 2017-11-19  7766.03  8101.91  7694.10   8036.49  3149320000   129595000000   \n",
       "4 2017-11-18  7697.21  7884.99  7463.44   7790.15  3667190000   128425000000   \n",
       "\n",
       "   eth_Open  eth_High  eth_Low  eth_Close  eth_Volume eth_Market Cap  \\\n",
       "0    360.31    381.42   360.15     380.65   800819000    34544000000   \n",
       "1    367.44    372.47   350.69     360.40   949912000    35220200000   \n",
       "2    354.09    372.14   353.29     366.73   807027000    33933400000   \n",
       "3    347.40    371.29   344.74     354.39  1181530000    33284900000   \n",
       "4    331.98    349.62   327.69     347.61   649639000    31800700000   \n",
       "\n",
       "   bt_day_diff  eth_day_diff  \n",
       "0     0.021738      0.056451  \n",
       "1    -0.016389     -0.019160  \n",
       "2     0.020098      0.035697  \n",
       "3     0.034826      0.020121  \n",
       "4     0.012075      0.047081  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "market_info = pd.merge(bitcoin_market_info, eth_market_info, on=['Date'])\n",
    "market_info = market_info[market_info['Date']>='2016-01-1']\n",
    "for coins in ['bt_', 'eth_']:\n",
    "    kwargs = { coins+'day_diff': lambda x: (x[coins+'Close']-x[coins+'Open'])/x[coins+'Open']}\n",
    "    market_info = market_info.assign(**kwargs)\n",
    "market_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for coins in ['bt_', 'eth_']:\n",
    "    kwargs = { coins + 'close_off_high': lambda x: 2*(x[coins + 'High'] - x[coins+'Close'])/(x[coins+'High']-x[coins+'Low'])-1,\n",
    "             coins + 'volatility': lambda x: (x[coins+'High']-x[coins+'Low'])/(x[coins+'Open'])}\n",
    "    market_info = market_info.assign(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>bt_Close</th>\n",
       "      <th>bt_Volume</th>\n",
       "      <th>bt_close_off_high</th>\n",
       "      <th>bt_volatility</th>\n",
       "      <th>eth_Close</th>\n",
       "      <th>eth_Volume</th>\n",
       "      <th>eth_close_off_high</th>\n",
       "      <th>eth_volatility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>434.33</td>\n",
       "      <td>36278900</td>\n",
       "      <td>-0.560641</td>\n",
       "      <td>0.020292</td>\n",
       "      <td>0.948024</td>\n",
       "      <td>206062</td>\n",
       "      <td>-0.418477</td>\n",
       "      <td>0.025040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>433.44</td>\n",
       "      <td>30096600</td>\n",
       "      <td>0.250597</td>\n",
       "      <td>0.009641</td>\n",
       "      <td>0.937124</td>\n",
       "      <td>255504</td>\n",
       "      <td>0.965898</td>\n",
       "      <td>0.034913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>430.01</td>\n",
       "      <td>39633800</td>\n",
       "      <td>-0.173865</td>\n",
       "      <td>0.020827</td>\n",
       "      <td>0.971905</td>\n",
       "      <td>407632</td>\n",
       "      <td>-0.317885</td>\n",
       "      <td>0.060792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>433.09</td>\n",
       "      <td>38477500</td>\n",
       "      <td>-0.474265</td>\n",
       "      <td>0.012649</td>\n",
       "      <td>0.954480</td>\n",
       "      <td>346245</td>\n",
       "      <td>-0.057657</td>\n",
       "      <td>0.047943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>431.96</td>\n",
       "      <td>34522600</td>\n",
       "      <td>-0.013333</td>\n",
       "      <td>0.010391</td>\n",
       "      <td>0.950176</td>\n",
       "      <td>219833</td>\n",
       "      <td>0.697930</td>\n",
       "      <td>0.025236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  bt_Close  bt_Volume  bt_close_off_high  bt_volatility  \\\n",
       "691 2016-01-01    434.33   36278900          -0.560641       0.020292   \n",
       "690 2016-01-02    433.44   30096600           0.250597       0.009641   \n",
       "689 2016-01-03    430.01   39633800          -0.173865       0.020827   \n",
       "688 2016-01-04    433.09   38477500          -0.474265       0.012649   \n",
       "687 2016-01-05    431.96   34522600          -0.013333       0.010391   \n",
       "\n",
       "     eth_Close  eth_Volume  eth_close_off_high  eth_volatility  \n",
       "691   0.948024      206062           -0.418477        0.025040  \n",
       "690   0.937124      255504            0.965898        0.034913  \n",
       "689   0.971905      407632           -0.317885        0.060792  \n",
       "688   0.954480      346245           -0.057657        0.047943  \n",
       "687   0.950176      219833            0.697930        0.025236  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data= market_info[['Date']+[coin+metric for coin in ['bt_','eth_']\n",
    "                                 for metric in ['Close', 'Volume', 'close_off_high','volatility']]]\n",
    "model_data = model_data.sort_values(by='Date')\n",
    "model_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split_date = '2017-06-01'\n",
    "training_set, test_set = model_data[model_data['Date']<split_date], model_data[model_data['Date']>split_date]\n",
    "training_set = training_set.drop('Date', 1)\n",
    "test_set = test_set.drop('Date', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "window_len = 10\n",
    "norm_cols = [coin+metric for coin in ['bt_', 'eth_'] for metric in ['Close', 'Volume']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LSTM_training_inputs = []\n",
    "for i in range(len(training_set)-window_len):\n",
    "    temp_set = training_set[i:(i+window_len)].copy()\n",
    "    for col in norm_cols:\n",
    "        temp_set.loc[:, col] = temp_set[col]/temp_set[col].iloc[0] -1\n",
    "    LSTM_training_inputs.append(temp_set)\n",
    "LSTM_training_outputs = (training_set['eth_Close'][window_len:].values/training_set['eth_Close'][:-window_len].values)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_test_inputs = []\n",
    "for i in range(len(test_set)- window_len):\n",
    "    temp_set = test_set[i:(i+window_len)].copy()\n",
    "    for col in norm_cols:\n",
    "        temp_set.loc[:,col] = temp_set[col]/temp_set[col].iloc[0] - 1\n",
    "    LSTM_test_inputs.append(temp_set)\n",
    "LSTM_test_outputs = (test_set['eth_Close'][window_len:].values/test_set['eth_Close'][:-window_len].values) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bt_Close</th>\n",
       "      <th>bt_Volume</th>\n",
       "      <th>bt_close_off_high</th>\n",
       "      <th>bt_volatility</th>\n",
       "      <th>eth_Close</th>\n",
       "      <th>eth_Volume</th>\n",
       "      <th>eth_close_off_high</th>\n",
       "      <th>eth_volatility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.560641</td>\n",
       "      <td>0.020292</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.418477</td>\n",
       "      <td>0.025040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>-0.002049</td>\n",
       "      <td>-0.170410</td>\n",
       "      <td>0.250597</td>\n",
       "      <td>0.009641</td>\n",
       "      <td>-0.011498</td>\n",
       "      <td>0.239937</td>\n",
       "      <td>0.965898</td>\n",
       "      <td>0.034913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>-0.009946</td>\n",
       "      <td>0.092475</td>\n",
       "      <td>-0.173865</td>\n",
       "      <td>0.020827</td>\n",
       "      <td>0.025190</td>\n",
       "      <td>0.978201</td>\n",
       "      <td>-0.317885</td>\n",
       "      <td>0.060792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>-0.002855</td>\n",
       "      <td>0.060603</td>\n",
       "      <td>-0.474265</td>\n",
       "      <td>0.012649</td>\n",
       "      <td>0.006810</td>\n",
       "      <td>0.680295</td>\n",
       "      <td>-0.057657</td>\n",
       "      <td>0.047943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>-0.005457</td>\n",
       "      <td>-0.048411</td>\n",
       "      <td>-0.013333</td>\n",
       "      <td>0.010391</td>\n",
       "      <td>0.002270</td>\n",
       "      <td>0.066829</td>\n",
       "      <td>0.697930</td>\n",
       "      <td>0.025236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>-0.012019</td>\n",
       "      <td>-0.061645</td>\n",
       "      <td>-0.003623</td>\n",
       "      <td>0.012782</td>\n",
       "      <td>0.002991</td>\n",
       "      <td>0.498534</td>\n",
       "      <td>-0.214540</td>\n",
       "      <td>0.026263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>0.054613</td>\n",
       "      <td>1.413585</td>\n",
       "      <td>-0.951499</td>\n",
       "      <td>0.069045</td>\n",
       "      <td>-0.006349</td>\n",
       "      <td>2.142074</td>\n",
       "      <td>0.681644</td>\n",
       "      <td>0.040587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>0.043515</td>\n",
       "      <td>0.570968</td>\n",
       "      <td>0.294196</td>\n",
       "      <td>0.032762</td>\n",
       "      <td>0.040890</td>\n",
       "      <td>1.647747</td>\n",
       "      <td>-0.806717</td>\n",
       "      <td>0.055274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>0.030576</td>\n",
       "      <td>-0.110282</td>\n",
       "      <td>0.814194</td>\n",
       "      <td>0.017094</td>\n",
       "      <td>0.040937</td>\n",
       "      <td>0.098121</td>\n",
       "      <td>-0.411897</td>\n",
       "      <td>0.019021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>0.031451</td>\n",
       "      <td>-0.007801</td>\n",
       "      <td>-0.919598</td>\n",
       "      <td>0.017758</td>\n",
       "      <td>0.054014</td>\n",
       "      <td>0.896944</td>\n",
       "      <td>-0.938235</td>\n",
       "      <td>0.025266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     bt_Close  bt_Volume  bt_close_off_high  bt_volatility  eth_Close  \\\n",
       "691  0.000000   0.000000          -0.560641       0.020292   0.000000   \n",
       "690 -0.002049  -0.170410           0.250597       0.009641  -0.011498   \n",
       "689 -0.009946   0.092475          -0.173865       0.020827   0.025190   \n",
       "688 -0.002855   0.060603          -0.474265       0.012649   0.006810   \n",
       "687 -0.005457  -0.048411          -0.013333       0.010391   0.002270   \n",
       "686 -0.012019  -0.061645          -0.003623       0.012782   0.002991   \n",
       "685  0.054613   1.413585          -0.951499       0.069045  -0.006349   \n",
       "684  0.043515   0.570968           0.294196       0.032762   0.040890   \n",
       "683  0.030576  -0.110282           0.814194       0.017094   0.040937   \n",
       "682  0.031451  -0.007801          -0.919598       0.017758   0.054014   \n",
       "\n",
       "     eth_Volume  eth_close_off_high  eth_volatility  \n",
       "691    0.000000           -0.418477        0.025040  \n",
       "690    0.239937            0.965898        0.034913  \n",
       "689    0.978201           -0.317885        0.060792  \n",
       "688    0.680295           -0.057657        0.047943  \n",
       "687    0.066829            0.697930        0.025236  \n",
       "686    0.498534           -0.214540        0.026263  \n",
       "685    2.142074            0.681644        0.040587  \n",
       "684    1.647747           -0.806717        0.055274  \n",
       "683    0.098121           -0.411897        0.019021  \n",
       "682    0.896944           -0.938235        0.025266  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM_training_inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LSTM_training_inputs = [np.array(LSTM_test_inputs) for LSTM_test_inputs in LSTM_test_inputs]\n",
    "LSTM_training_inputs = np.array(LSTM_test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LSTM_test_inputs = [np.array(LSTM_test_inputs) for LSTM_test_inputs in LSTM_test_inputs]\n",
    "LSTM_test_inputs = np.array(LSTM_test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the relevant Keras modules\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "\n",
    "\n",
    "def build_model(inputs, output_size, neurons, activ_func =\"linear\",\n",
    "               dropout=0.25, loss= \"mse\", optimizer=\"adam\"):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(neurons, input_shape=(inputs.shape[0], inputs.shape[1])))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(units=output_size))\n",
    "    model.add(Activation(activ_func))\n",
    "    \n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### np.random.seed(202)\n",
    "eth_model = build_model(LSTM_training_inputs, output_size=1, neurons = 20)\n",
    "LSTM_training_outputs = (training_set['eth_Close'][window_len:].values/training_set['eth_Close'][:-window_len].values)-1\n",
    "\n",
    "eth_history = eth_model.fit(LSTM_training_inputs, LSTM_training_outputs,\n",
    "                           epochs=50, batch_size=1, verbose=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected lstm_5_input to have 3 dimensions, but got array with shape (10, 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-ed467d4d1110>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mLSTM_training_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eth_Close'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwindow_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eth_Close'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mwindow_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m eth_history = eth_model.fit(LSTM_training_inputs, LSTM_training_outputs,\n\u001b[0;32m----> 5\u001b[0;31m                            epochs=50, batch_size=1, verbose=2, shuffle=True)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1520\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1521\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1522\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1523\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1524\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1376\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1378\u001b[0;31m                                     exception_prefix='input')\n\u001b[0m\u001b[1;32m   1379\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[1;32m   1380\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    130\u001b[0m                                  \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                                  \u001b[0;34m' dimensions, but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                                  str(array.shape))\n\u001b[0m\u001b[1;32m    133\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected lstm_5_input to have 3 dimensions, but got array with shape (10, 8)"
     ]
    }
   ],
   "source": [
    "np.random.seed(202)\n",
    "eth_model = build_model(LSTM_training_inputs, output_size=1, neurons = 20)\n",
    "LSTM_training_outputs = (training_set['eth_Close'][window_len:].values/training_set['eth_Close'][:-window_len].values) -1\n",
    "eth_history = eth_model.fit(LSTM_training_inputs, LSTM_training_outputs,\n",
    "                           epochs=50, batch_size=1, verbose=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
